{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4963f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is the implementations for our integration framework, including z-score standardization, feature construction, and multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load raw score CSV files from different models (replace with actual paths as needed)\n",
    "df1 = pd.read_csv('rotate_rawscore.csv', index_col=0)\n",
    "df2 = pd.read_csv('transe_rawscore.csv', index_col=0)\n",
    "df3 = pd.read_csv('distmult_rawscore.csv', index_col=0)\n",
    "df4 = pd.read_csv('originbert_rawscore.csv', index_col=0)\n",
    "df5 = pd.read_csv('pubmedbert_rawscore.csv', index_col=0)\n",
    "df6 = pd.read_csv('biobert_rawscore.csv', index_col=0)\n",
    "df7 = pd.read_csv('GLM2_rawscore.csv', index_col=0)\n",
    "df8 = pd.read_csv('GLM4_rawscore.csv', index_col=0)\n",
    "df9 = pd.read_csv('llama3_rawscore.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2971420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform z-score standardization\n",
    "def standardize(df):\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "# Apply z-score standardization (negate if lower scores indicate better performance)\n",
    "df1_standardized = -standardize(df1)  # RotatE\n",
    "df2_standardized = -standardize(df2)  # TransE\n",
    "df3_standardized = -standardize(df3)  # DistMult\n",
    "df4_standardized =  standardize(df4)  # OriginBERT\n",
    "df5_standardized =  standardize(df5)  # PubMedBERT\n",
    "df6_standardized =  standardize(df6)  # BioBERT\n",
    "df7_standardized = -standardize(df7)  # GLM2\n",
    "df8_standardized = -standardize(df8)  # GLM4\n",
    "df9_standardized = -standardize(df9)  # LLaMA3\n",
    "\n",
    "# Optionally save standardized scores to CSV\n",
    "# df1_standardized.to_csv('rotate_standardized.csv')\n",
    "# df2_standardized.to_csv('transe_standardized.csv')\n",
    "# df7_standardized.to_csv('glm2_standardized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9544b8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>99990</th>\n",
       "      <th>99991</th>\n",
       "      <th>99992</th>\n",
       "      <th>99993</th>\n",
       "      <th>99994</th>\n",
       "      <th>99995</th>\n",
       "      <th>99996</th>\n",
       "      <th>99997</th>\n",
       "      <th>99998</th>\n",
       "      <th>99999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.377382</td>\n",
       "      <td>-1.697837</td>\n",
       "      <td>-1.943951</td>\n",
       "      <td>-1.668762</td>\n",
       "      <td>-1.613251</td>\n",
       "      <td>-1.330229</td>\n",
       "      <td>-1.903594</td>\n",
       "      <td>-1.737525</td>\n",
       "      <td>-1.995660</td>\n",
       "      <td>-1.639659</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.799382</td>\n",
       "      <td>-2.071293</td>\n",
       "      <td>-2.151686</td>\n",
       "      <td>-2.419662</td>\n",
       "      <td>-1.426277</td>\n",
       "      <td>-1.160419</td>\n",
       "      <td>-1.660245</td>\n",
       "      <td>-1.877634</td>\n",
       "      <td>-2.321295</td>\n",
       "      <td>-0.830214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.826185</td>\n",
       "      <td>0.772493</td>\n",
       "      <td>0.815928</td>\n",
       "      <td>-0.023804</td>\n",
       "      <td>1.321514</td>\n",
       "      <td>0.225860</td>\n",
       "      <td>1.066769</td>\n",
       "      <td>0.733854</td>\n",
       "      <td>0.342386</td>\n",
       "      <td>0.730652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739880</td>\n",
       "      <td>0.895820</td>\n",
       "      <td>0.314436</td>\n",
       "      <td>0.855254</td>\n",
       "      <td>-0.168045</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>-0.298745</td>\n",
       "      <td>0.711504</td>\n",
       "      <td>0.797039</td>\n",
       "      <td>0.872778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.474348</td>\n",
       "      <td>0.413584</td>\n",
       "      <td>0.297986</td>\n",
       "      <td>1.286691</td>\n",
       "      <td>-0.456406</td>\n",
       "      <td>0.621896</td>\n",
       "      <td>-0.645325</td>\n",
       "      <td>0.353906</td>\n",
       "      <td>0.261807</td>\n",
       "      <td>-0.399480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653371</td>\n",
       "      <td>-0.170532</td>\n",
       "      <td>0.475424</td>\n",
       "      <td>0.774526</td>\n",
       "      <td>0.016196</td>\n",
       "      <td>-0.305831</td>\n",
       "      <td>-0.545865</td>\n",
       "      <td>0.076566</td>\n",
       "      <td>1.177253</td>\n",
       "      <td>-0.008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.600689</td>\n",
       "      <td>-1.226149</td>\n",
       "      <td>-0.612714</td>\n",
       "      <td>-1.026923</td>\n",
       "      <td>-0.402768</td>\n",
       "      <td>-1.484344</td>\n",
       "      <td>-0.959813</td>\n",
       "      <td>-1.878992</td>\n",
       "      <td>-1.665685</td>\n",
       "      <td>-0.897124</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.610709</td>\n",
       "      <td>-1.152627</td>\n",
       "      <td>-1.479741</td>\n",
       "      <td>-1.292332</td>\n",
       "      <td>0.378474</td>\n",
       "      <td>0.075556</td>\n",
       "      <td>-0.453551</td>\n",
       "      <td>-1.691993</td>\n",
       "      <td>-1.362934</td>\n",
       "      <td>0.384441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.514298</td>\n",
       "      <td>-0.859692</td>\n",
       "      <td>-0.059669</td>\n",
       "      <td>-1.334569</td>\n",
       "      <td>-0.031718</td>\n",
       "      <td>-1.296103</td>\n",
       "      <td>0.468098</td>\n",
       "      <td>0.036833</td>\n",
       "      <td>-0.488059</td>\n",
       "      <td>-0.152042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701893</td>\n",
       "      <td>0.135620</td>\n",
       "      <td>-0.739676</td>\n",
       "      <td>0.151289</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>0.532161</td>\n",
       "      <td>-0.101293</td>\n",
       "      <td>0.285262</td>\n",
       "      <td>-0.559335</td>\n",
       "      <td>-0.473017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1.830571</td>\n",
       "      <td>1.116601</td>\n",
       "      <td>1.262269</td>\n",
       "      <td>1.000875</td>\n",
       "      <td>1.122549</td>\n",
       "      <td>0.434990</td>\n",
       "      <td>1.251139</td>\n",
       "      <td>0.609702</td>\n",
       "      <td>0.932668</td>\n",
       "      <td>1.144710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861465</td>\n",
       "      <td>1.216625</td>\n",
       "      <td>0.933399</td>\n",
       "      <td>1.118462</td>\n",
       "      <td>2.863923</td>\n",
       "      <td>1.716343</td>\n",
       "      <td>1.589564</td>\n",
       "      <td>0.613056</td>\n",
       "      <td>1.132187</td>\n",
       "      <td>1.591988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.316004</td>\n",
       "      <td>0.205787</td>\n",
       "      <td>0.065632</td>\n",
       "      <td>-0.580883</td>\n",
       "      <td>0.664475</td>\n",
       "      <td>-0.737694</td>\n",
       "      <td>1.021948</td>\n",
       "      <td>0.676751</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.234669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495186</td>\n",
       "      <td>0.523622</td>\n",
       "      <td>0.029102</td>\n",
       "      <td>0.120659</td>\n",
       "      <td>0.686121</td>\n",
       "      <td>0.649166</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.566072</td>\n",
       "      <td>-0.340194</td>\n",
       "      <td>0.079401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1.910690</td>\n",
       "      <td>1.488091</td>\n",
       "      <td>0.980284</td>\n",
       "      <td>1.478987</td>\n",
       "      <td>1.759335</td>\n",
       "      <td>1.514889</td>\n",
       "      <td>1.553759</td>\n",
       "      <td>1.605498</td>\n",
       "      <td>1.532393</td>\n",
       "      <td>1.641135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980554</td>\n",
       "      <td>1.483632</td>\n",
       "      <td>1.563776</td>\n",
       "      <td>1.338451</td>\n",
       "      <td>2.582066</td>\n",
       "      <td>2.281596</td>\n",
       "      <td>2.044823</td>\n",
       "      <td>1.345021</td>\n",
       "      <td>1.206412</td>\n",
       "      <td>1.935544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>0.410679</td>\n",
       "      <td>0.716843</td>\n",
       "      <td>0.541846</td>\n",
       "      <td>-0.152226</td>\n",
       "      <td>0.365107</td>\n",
       "      <td>-0.402259</td>\n",
       "      <td>0.907830</td>\n",
       "      <td>0.457059</td>\n",
       "      <td>0.421601</td>\n",
       "      <td>0.408263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.351269</td>\n",
       "      <td>0.856360</td>\n",
       "      <td>0.481431</td>\n",
       "      <td>0.783352</td>\n",
       "      <td>1.085182</td>\n",
       "      <td>1.755894</td>\n",
       "      <td>1.014308</td>\n",
       "      <td>0.408840</td>\n",
       "      <td>0.218387</td>\n",
       "      <td>0.044782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0.950683</td>\n",
       "      <td>0.550487</td>\n",
       "      <td>0.238125</td>\n",
       "      <td>0.367525</td>\n",
       "      <td>1.000052</td>\n",
       "      <td>-0.155117</td>\n",
       "      <td>1.008703</td>\n",
       "      <td>0.737169</td>\n",
       "      <td>1.138207</td>\n",
       "      <td>0.734970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477856</td>\n",
       "      <td>0.491280</td>\n",
       "      <td>0.753789</td>\n",
       "      <td>0.812813</td>\n",
       "      <td>1.332976</td>\n",
       "      <td>0.976877</td>\n",
       "      <td>1.489617</td>\n",
       "      <td>0.908289</td>\n",
       "      <td>0.154891</td>\n",
       "      <td>0.617949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>645 rows × 100000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -1.377382 -1.697837 -1.943951 -1.668762 -1.613251 -1.330229 -1.903594   \n",
       "1    0.826185  0.772493  0.815928 -0.023804  1.321514  0.225860  1.066769   \n",
       "2    0.474348  0.413584  0.297986  1.286691 -0.456406  0.621896 -0.645325   \n",
       "3   -0.600689 -1.226149 -0.612714 -1.026923 -0.402768 -1.484344 -0.959813   \n",
       "4   -0.514298 -0.859692 -0.059669 -1.334569 -0.031718 -1.296103  0.468098   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "640  1.830571  1.116601  1.262269  1.000875  1.122549  0.434990  1.251139   \n",
       "641  0.316004  0.205787  0.065632 -0.580883  0.664475 -0.737694  1.021948   \n",
       "642  1.910690  1.488091  0.980284  1.478987  1.759335  1.514889  1.553759   \n",
       "643  0.410679  0.716843  0.541846 -0.152226  0.365107 -0.402259  0.907830   \n",
       "644  0.950683  0.550487  0.238125  0.367525  1.000052 -0.155117  1.008703   \n",
       "\n",
       "            7         8         9  ...     99990     99991     99992  \\\n",
       "0   -1.737525 -1.995660 -1.639659  ... -2.799382 -2.071293 -2.151686   \n",
       "1    0.733854  0.342386  0.730652  ...  0.739880  0.895820  0.314436   \n",
       "2    0.353906  0.261807 -0.399480  ...  0.653371 -0.170532  0.475424   \n",
       "3   -1.878992 -1.665685 -0.897124  ... -1.610709 -1.152627 -1.479741   \n",
       "4    0.036833 -0.488059 -0.152042  ...  0.701893  0.135620 -0.739676   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "640  0.609702  0.932668  1.144710  ...  0.861465  1.216625  0.933399   \n",
       "641  0.676751  0.026471  0.234669  ...  0.495186  0.523622  0.029102   \n",
       "642  1.605498  1.532393  1.641135  ...  0.980554  1.483632  1.563776   \n",
       "643  0.457059  0.421601  0.408263  ...  1.351269  0.856360  0.481431   \n",
       "644  0.737169  1.138207  0.734970  ...  0.477856  0.491280  0.753789   \n",
       "\n",
       "        99993     99994     99995     99996     99997     99998     99999  \n",
       "0   -2.419662 -1.426277 -1.160419 -1.660245 -1.877634 -2.321295 -0.830214  \n",
       "1    0.855254 -0.168045 -0.004135 -0.298745  0.711504  0.797039  0.872778  \n",
       "2    0.774526  0.016196 -0.305831 -0.545865  0.076566  1.177253 -0.008981  \n",
       "3   -1.292332  0.378474  0.075556 -0.453551 -1.691993 -1.362934  0.384441  \n",
       "4    0.151289  0.031322  0.532161 -0.101293  0.285262 -0.559335 -0.473017  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "640  1.118462  2.863923  1.716343  1.589564  0.613056  1.132187  1.591988  \n",
       "641  0.120659  0.686121  0.649166  0.999652  0.566072 -0.340194  0.079401  \n",
       "642  1.338451  2.582066  2.281596  2.044823  1.345021  1.206412  1.935544  \n",
       "643  0.783352  1.085182  1.755894  1.014308  0.408840  0.218387  0.044782  \n",
       "644  0.812813  1.332976  0.976877  1.489617  0.908289  0.154891  0.617949  \n",
       "\n",
       "[645 rows x 100000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfffa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 576,\n",
       " 1: 346,\n",
       " 2: 520,\n",
       " 3: 224,\n",
       " 4: 618,\n",
       " 5: 285,\n",
       " 6: 509,\n",
       " 7: 634,\n",
       " 8: 614,\n",
       " 9: 564,\n",
       " 10: 444,\n",
       " 11: 320,\n",
       " 12: 476,\n",
       " 13: 529,\n",
       " 14: 569,\n",
       " 15: 639,\n",
       " 16: 453,\n",
       " 17: 634,\n",
       " 18: 21,\n",
       " 19: 516,\n",
       " 20: 240,\n",
       " 21: 530,\n",
       " 22: 603,\n",
       " 23: 347,\n",
       " 24: 405,\n",
       " 25: 623,\n",
       " 26: 176,\n",
       " 27: 605,\n",
       " 28: 563,\n",
       " 29: 228,\n",
       " 30: 118,\n",
       " 31: 621,\n",
       " 32: 315,\n",
       " 33: 619,\n",
       " 34: 626,\n",
       " 35: 503,\n",
       " 36: 530,\n",
       " 37: 33,\n",
       " 38: 458,\n",
       " 39: 420,\n",
       " 40: 509,\n",
       " 41: 245,\n",
       " 42: 150,\n",
       " 43: 392,\n",
       " 44: 485,\n",
       " 45: 292,\n",
       " 46: 106,\n",
       " 47: 509,\n",
       " 48: 148,\n",
       " 49: 15,\n",
       " 50: 485,\n",
       " 51: 543,\n",
       " 52: 436,\n",
       " 53: 569,\n",
       " 54: 369,\n",
       " 55: 184,\n",
       " 56: 538,\n",
       " 57: 344,\n",
       " 58: 320,\n",
       " 59: 327,\n",
       " 60: 605,\n",
       " 61: 137,\n",
       " 62: 22,\n",
       " 63: 434,\n",
       " 64: 47,\n",
       " 65: 292,\n",
       " 66: 623,\n",
       " 67: 190,\n",
       " 68: 39,\n",
       " 69: 642,\n",
       " 70: 260,\n",
       " 71: 642,\n",
       " 72: 348,\n",
       " 73: 152,\n",
       " 74: 413,\n",
       " 75: 494,\n",
       " 76: 590,\n",
       " 77: 157,\n",
       " 78: 521,\n",
       " 79: 220,\n",
       " 80: 436,\n",
       " 81: 226,\n",
       " 82: 258,\n",
       " 83: 271,\n",
       " 84: 98,\n",
       " 85: 405,\n",
       " 86: 397,\n",
       " 87: 278,\n",
       " 88: 315,\n",
       " 89: 634,\n",
       " 90: 245,\n",
       " 91: 285,\n",
       " 92: 141,\n",
       " 93: 436,\n",
       " 94: 176,\n",
       " 95: 84,\n",
       " 96: 2,\n",
       " 97: 228,\n",
       " 98: 506,\n",
       " 99: 349,\n",
       " 100: 149,\n",
       " 101: 551,\n",
       " 102: 547,\n",
       " 103: 9,\n",
       " 104: 148,\n",
       " 105: 425,\n",
       " 106: 492,\n",
       " 107: 194,\n",
       " 108: 620,\n",
       " 109: 358,\n",
       " 110: 571,\n",
       " 111: 279,\n",
       " 112: 375,\n",
       " 113: 142,\n",
       " 114: 418,\n",
       " 115: 139,\n",
       " 116: 619,\n",
       " 117: 199,\n",
       " 118: 438,\n",
       " 119: 552,\n",
       " 120: 599,\n",
       " 121: 529,\n",
       " 122: 251,\n",
       " 123: 186,\n",
       " 124: 341,\n",
       " 125: 622,\n",
       " 126: 524,\n",
       " 127: 267,\n",
       " 128: 456,\n",
       " 129: 182,\n",
       " 130: 569,\n",
       " 131: 475,\n",
       " 132: 22,\n",
       " 133: 99,\n",
       " 134: 371,\n",
       " 135: 378,\n",
       " 136: 327,\n",
       " 137: 618,\n",
       " 138: 560,\n",
       " 139: 394,\n",
       " 140: 57,\n",
       " 141: 621,\n",
       " 142: 521,\n",
       " 143: 624,\n",
       " 144: 623,\n",
       " 145: 420,\n",
       " 146: 634,\n",
       " 147: 376,\n",
       " 148: 503,\n",
       " 149: 569,\n",
       " 150: 456,\n",
       " 151: 248,\n",
       " 152: 348,\n",
       " 153: 230,\n",
       " 154: 591,\n",
       " 155: 596,\n",
       " 156: 396,\n",
       " 157: 22,\n",
       " 158: 355,\n",
       " 159: 511,\n",
       " 160: 182,\n",
       " 161: 515,\n",
       " 162: 494,\n",
       " 163: 266,\n",
       " 164: 106,\n",
       " 165: 193,\n",
       " 166: 148,\n",
       " 167: 375,\n",
       " 168: 285,\n",
       " 169: 324,\n",
       " 170: 636,\n",
       " 171: 442,\n",
       " 172: 605,\n",
       " 173: 623,\n",
       " 174: 75,\n",
       " 175: 621,\n",
       " 176: 147,\n",
       " 177: 458,\n",
       " 178: 315,\n",
       " 179: 67,\n",
       " 180: 219,\n",
       " 181: 54,\n",
       " 182: 530,\n",
       " 183: 212,\n",
       " 184: 291,\n",
       " 185: 174,\n",
       " 186: 118,\n",
       " 187: 210,\n",
       " 188: 390,\n",
       " 189: 543,\n",
       " 190: 448,\n",
       " 191: 327,\n",
       " 192: 152,\n",
       " 193: 433,\n",
       " 194: 599,\n",
       " 195: 150,\n",
       " 196: 351,\n",
       " 197: 618,\n",
       " 198: 506,\n",
       " 199: 176,\n",
       " 200: 436,\n",
       " 201: 315,\n",
       " 202: 198,\n",
       " 203: 245,\n",
       " 204: 437,\n",
       " 205: 448,\n",
       " 206: 484,\n",
       " 207: 606,\n",
       " 208: 504,\n",
       " 209: 640,\n",
       " 210: 492,\n",
       " 211: 444,\n",
       " 212: 77,\n",
       " 213: 285,\n",
       " 214: 292,\n",
       " 215: 453,\n",
       " 216: 547,\n",
       " 217: 396,\n",
       " 218: 591,\n",
       " 219: 104,\n",
       " 220: 621,\n",
       " 221: 196,\n",
       " 222: 226,\n",
       " 223: 621,\n",
       " 224: 563,\n",
       " 225: 157,\n",
       " 226: 224,\n",
       " 227: 324,\n",
       " 228: 540,\n",
       " 229: 595,\n",
       " 230: 434,\n",
       " 231: 395,\n",
       " 232: 22,\n",
       " 233: 634,\n",
       " 234: 618,\n",
       " 235: 585,\n",
       " 236: 595,\n",
       " 237: 179,\n",
       " 238: 431,\n",
       " 239: 303,\n",
       " 240: 640,\n",
       " 241: 153,\n",
       " 242: 248,\n",
       " 243: 485,\n",
       " 244: 569,\n",
       " 245: 638,\n",
       " 246: 320,\n",
       " 247: 226,\n",
       " 248: 258,\n",
       " 249: 642,\n",
       " 250: 245,\n",
       " 251: 315,\n",
       " 252: 534,\n",
       " 253: 404,\n",
       " 254: 543,\n",
       " 255: 567,\n",
       " 256: 484,\n",
       " 257: 75,\n",
       " 258: 529,\n",
       " 259: 490,\n",
       " 260: 258,\n",
       " 261: 526,\n",
       " 262: 478,\n",
       " 263: 618,\n",
       " 264: 503,\n",
       " 265: 298,\n",
       " 266: 371,\n",
       " 267: 396,\n",
       " 268: 344,\n",
       " 269: 343,\n",
       " 270: 224,\n",
       " 271: 224,\n",
       " 272: 185,\n",
       " 273: 599,\n",
       " 274: 348,\n",
       " 275: 520,\n",
       " 276: 481,\n",
       " 277: 484,\n",
       " 278: 526,\n",
       " 279: 614,\n",
       " 280: 396,\n",
       " 281: 551,\n",
       " 282: 526,\n",
       " 283: 548,\n",
       " 284: 526,\n",
       " 285: 265,\n",
       " 286: 225,\n",
       " 287: 508,\n",
       " 288: 566,\n",
       " 289: 291,\n",
       " 290: 294,\n",
       " 291: 173,\n",
       " 292: 272,\n",
       " 293: 117,\n",
       " 294: 375,\n",
       " 295: 331,\n",
       " 296: 560,\n",
       " 297: 475,\n",
       " 298: 548,\n",
       " 299: 615,\n",
       " 300: 564,\n",
       " 301: 121,\n",
       " 302: 592,\n",
       " 303: 634,\n",
       " 304: 49,\n",
       " 305: 94,\n",
       " 306: 509,\n",
       " 307: 508,\n",
       " 308: 293,\n",
       " 309: 376,\n",
       " 310: 642,\n",
       " 311: 198,\n",
       " 312: 384,\n",
       " 313: 560,\n",
       " 314: 227,\n",
       " 315: 348,\n",
       " 316: 603,\n",
       " 317: 293,\n",
       " 318: 444,\n",
       " 319: 605,\n",
       " 320: 431,\n",
       " 321: 320,\n",
       " 322: 348,\n",
       " 323: 253,\n",
       " 324: 117,\n",
       " 325: 506,\n",
       " 326: 441,\n",
       " 327: 540,\n",
       " 328: 272,\n",
       " 329: 617,\n",
       " 330: 526,\n",
       " 331: 396,\n",
       " 332: 275,\n",
       " 333: 294,\n",
       " 334: 508,\n",
       " 335: 320,\n",
       " 336: 456,\n",
       " 337: 615,\n",
       " 338: 548,\n",
       " 339: 224,\n",
       " 340: 84,\n",
       " 341: 309,\n",
       " 342: 440,\n",
       " 343: 539,\n",
       " 344: 509,\n",
       " 345: 94,\n",
       " 346: 141,\n",
       " 347: 435,\n",
       " 348: 376,\n",
       " 349: 533,\n",
       " 350: 435,\n",
       " 351: 90,\n",
       " 352: 416,\n",
       " 353: 395,\n",
       " 354: 526,\n",
       " 355: 331,\n",
       " 356: 244,\n",
       " 357: 521,\n",
       " 358: 446,\n",
       " 359: 171,\n",
       " 360: 568,\n",
       " 361: 552,\n",
       " 362: 563,\n",
       " 363: 544,\n",
       " 364: 395,\n",
       " 365: 346,\n",
       " 366: 508,\n",
       " 367: 530,\n",
       " 368: 397,\n",
       " 369: 393,\n",
       " 370: 143,\n",
       " 371: 137,\n",
       " 372: 53,\n",
       " 373: 618,\n",
       " 374: 542,\n",
       " 375: 155,\n",
       " 376: 355,\n",
       " 377: 614,\n",
       " 378: 551,\n",
       " 379: 609,\n",
       " 380: 504,\n",
       " 381: 182,\n",
       " 382: 378,\n",
       " 383: 560,\n",
       " 384: 366,\n",
       " 385: 172,\n",
       " 386: 404,\n",
       " 387: 439,\n",
       " 388: 155,\n",
       " 389: 503,\n",
       " 390: 172,\n",
       " 391: 172,\n",
       " 392: 436,\n",
       " 393: 491,\n",
       " 394: 277,\n",
       " 395: 486,\n",
       " 396: 378,\n",
       " 397: 78,\n",
       " 398: 530,\n",
       " 399: 478,\n",
       " 400: 533,\n",
       " 401: 395,\n",
       " 402: 397,\n",
       " 403: 228,\n",
       " 404: 436,\n",
       " 405: 603,\n",
       " 406: 252,\n",
       " 407: 436,\n",
       " 408: 615,\n",
       " 409: 484,\n",
       " 410: 572,\n",
       " 411: 635,\n",
       " 412: 335,\n",
       " 413: 359,\n",
       " 414: 481,\n",
       " 415: 404,\n",
       " 416: 358,\n",
       " 417: 526,\n",
       " 418: 320,\n",
       " 419: 436,\n",
       " 420: 567,\n",
       " 421: 355,\n",
       " 422: 526,\n",
       " 423: 149,\n",
       " 424: 317,\n",
       " 425: 529,\n",
       " 426: 458,\n",
       " 427: 370,\n",
       " 428: 396,\n",
       " 429: 102,\n",
       " 430: 22,\n",
       " 431: 245,\n",
       " 432: 612,\n",
       " 433: 364,\n",
       " 434: 376,\n",
       " 435: 491,\n",
       " 436: 75,\n",
       " 437: 434,\n",
       " 438: 152,\n",
       " 439: 516,\n",
       " 440: 595,\n",
       " 441: 623,\n",
       " 442: 272,\n",
       " 443: 184,\n",
       " 444: 532,\n",
       " 445: 384,\n",
       " 446: 9,\n",
       " 447: 571,\n",
       " 448: 227,\n",
       " 449: 618,\n",
       " 450: 291,\n",
       " 451: 569,\n",
       " 452: 623,\n",
       " 453: 106,\n",
       " 454: 485,\n",
       " 455: 526,\n",
       " 456: 157,\n",
       " 457: 393,\n",
       " 458: 435,\n",
       " 459: 369,\n",
       " 460: 516,\n",
       " 461: 395,\n",
       " 462: 526,\n",
       " 463: 193,\n",
       " 464: 390,\n",
       " 465: 560,\n",
       " 466: 509,\n",
       " 467: 293,\n",
       " 468: 542,\n",
       " 469: 490,\n",
       " 470: 552,\n",
       " 471: 375,\n",
       " 472: 589,\n",
       " 473: 642,\n",
       " 474: 198,\n",
       " 475: 149,\n",
       " 476: 484,\n",
       " 477: 405,\n",
       " 478: 574,\n",
       " 479: 552,\n",
       " 480: 294,\n",
       " 481: 75,\n",
       " 482: 293,\n",
       " 483: 303,\n",
       " 484: 513,\n",
       " 485: 22,\n",
       " 486: 484,\n",
       " 487: 274,\n",
       " 488: 447,\n",
       " 489: 621,\n",
       " 490: 377,\n",
       " 491: 426,\n",
       " 492: 458,\n",
       " 493: 52,\n",
       " 494: 510,\n",
       " 495: 412,\n",
       " 496: 590,\n",
       " 497: 613,\n",
       " 498: 543,\n",
       " 499: 491,\n",
       " 500: 416,\n",
       " 501: 391,\n",
       " 502: 575,\n",
       " 503: 568,\n",
       " 504: 141,\n",
       " 505: 396,\n",
       " 506: 435,\n",
       " 507: 177,\n",
       " 508: 212,\n",
       " 509: 564,\n",
       " 510: 349,\n",
       " 511: 605,\n",
       " 512: 218,\n",
       " 513: 266,\n",
       " 514: 121,\n",
       " 515: 98,\n",
       " 516: 176,\n",
       " 517: 599,\n",
       " 518: 599,\n",
       " 519: 437,\n",
       " 520: 599,\n",
       " 521: 47,\n",
       " 522: 545,\n",
       " 523: 47,\n",
       " 524: 118,\n",
       " 525: 485,\n",
       " 526: 598,\n",
       " 527: 449,\n",
       " 528: 341,\n",
       " 529: 530,\n",
       " 530: 101,\n",
       " 531: 605,\n",
       " 532: 434,\n",
       " 533: 287,\n",
       " 534: 531,\n",
       " 535: 558,\n",
       " 536: 434,\n",
       " 537: 494,\n",
       " 538: 315,\n",
       " 539: 458,\n",
       " 540: 309,\n",
       " 541: 326,\n",
       " 542: 434,\n",
       " 543: 326,\n",
       " 544: 229,\n",
       " 545: 436,\n",
       " 546: 506,\n",
       " 547: 438,\n",
       " 548: 568,\n",
       " 549: 543,\n",
       " 550: 620,\n",
       " 551: 567,\n",
       " 552: 596,\n",
       " 553: 619,\n",
       " 554: 344,\n",
       " 555: 482,\n",
       " 556: 193,\n",
       " 557: 539,\n",
       " 558: 315,\n",
       " 559: 599,\n",
       " 560: 346,\n",
       " 561: 558,\n",
       " 562: 279,\n",
       " 563: 412,\n",
       " 564: 640,\n",
       " 565: 426,\n",
       " 566: 495,\n",
       " 567: 572,\n",
       " 568: 507,\n",
       " 569: 379,\n",
       " 570: 362,\n",
       " 571: 233,\n",
       " 572: 456,\n",
       " 573: 378,\n",
       " 574: 530,\n",
       " 575: 49,\n",
       " 576: 121,\n",
       " 577: 47,\n",
       " 578: 378,\n",
       " 579: 143,\n",
       " 580: 331,\n",
       " 581: 458,\n",
       " 582: 529,\n",
       " 583: 192,\n",
       " 584: 76,\n",
       " 585: 67,\n",
       " 586: 245,\n",
       " 587: 173,\n",
       " 588: 639,\n",
       " 589: 381,\n",
       " 590: 526,\n",
       " 591: 492,\n",
       " 592: 434,\n",
       " 593: 538,\n",
       " 594: 448,\n",
       " 595: 529,\n",
       " 596: 431,\n",
       " 597: 338,\n",
       " 598: 618,\n",
       " 599: 376,\n",
       " 600: 341,\n",
       " 601: 391,\n",
       " 602: 143,\n",
       " 603: 643,\n",
       " 604: 75,\n",
       " 605: 619,\n",
       " 606: 253,\n",
       " 607: 614,\n",
       " 608: 223,\n",
       " 609: 95,\n",
       " 610: 289,\n",
       " 611: 515,\n",
       " 612: 558,\n",
       " 613: 585,\n",
       " 614: 260,\n",
       " 615: 558,\n",
       " 616: 458,\n",
       " 617: 492,\n",
       " 618: 621,\n",
       " 619: 569,\n",
       " 620: 484,\n",
       " 621: 452,\n",
       " 622: 615,\n",
       " 623: 246,\n",
       " 624: 482,\n",
       " 625: 349,\n",
       " 626: 275,\n",
       " 627: 486,\n",
       " 628: 7,\n",
       " 629: 102,\n",
       " 630: 103,\n",
       " 631: 177,\n",
       " 632: 506,\n",
       " 633: 198,\n",
       " 634: 378,\n",
       " 635: 2,\n",
       " 636: 320,\n",
       " 637: 135,\n",
       " 638: 548,\n",
       " 639: 386,\n",
       " 640: 439,\n",
       " 641: 285,\n",
       " 642: 258,\n",
       " 643: 481,\n",
       " 644: 503,\n",
       " 645: 315,\n",
       " 646: 438,\n",
       " 647: 481,\n",
       " 648: 293,\n",
       " 649: 567,\n",
       " 650: 520,\n",
       " 651: 506,\n",
       " 652: 642,\n",
       " 653: 509,\n",
       " 654: 212,\n",
       " 655: 507,\n",
       " 656: 529,\n",
       " 657: 485,\n",
       " 658: 224,\n",
       " 659: 503,\n",
       " 660: 480,\n",
       " 661: 92,\n",
       " 662: 538,\n",
       " 663: 605,\n",
       " 664: 504,\n",
       " 665: 250,\n",
       " 666: 362,\n",
       " 667: 220,\n",
       " 668: 599,\n",
       " 669: 475,\n",
       " 670: 623,\n",
       " 671: 386,\n",
       " 672: 638,\n",
       " 673: 117,\n",
       " 674: 258,\n",
       " 675: 592,\n",
       " 676: 508,\n",
       " 677: 230,\n",
       " 678: 543,\n",
       " 679: 590,\n",
       " 680: 613,\n",
       " 681: 628,\n",
       " 682: 75,\n",
       " 683: 94,\n",
       " 684: 541,\n",
       " 685: 482,\n",
       " 686: 204,\n",
       " 687: 515,\n",
       " 688: 504,\n",
       " 689: 526,\n",
       " 690: 374,\n",
       " 691: 291,\n",
       " 692: 543,\n",
       " 693: 533,\n",
       " 694: 441,\n",
       " 695: 590,\n",
       " 696: 526,\n",
       " 697: 421,\n",
       " 698: 376,\n",
       " 699: 366,\n",
       " 700: 260,\n",
       " 701: 494,\n",
       " 702: 603,\n",
       " 703: 141,\n",
       " 704: 43,\n",
       " 705: 240,\n",
       " 706: 393,\n",
       " 707: 25,\n",
       " 708: 623,\n",
       " 709: 558,\n",
       " 710: 448,\n",
       " 711: 330,\n",
       " 712: 420,\n",
       " 713: 99,\n",
       " 714: 431,\n",
       " 715: 22,\n",
       " 716: 393,\n",
       " 717: 450,\n",
       " 718: 436,\n",
       " 719: 615,\n",
       " 720: 521,\n",
       " 721: 538,\n",
       " 722: 351,\n",
       " 723: 344,\n",
       " 724: 509,\n",
       " 725: 320,\n",
       " 726: 526,\n",
       " 727: 225,\n",
       " 728: 22,\n",
       " 729: 32,\n",
       " 730: 539,\n",
       " 731: 393,\n",
       " 732: 640,\n",
       " 733: 456,\n",
       " 734: 313,\n",
       " 735: 380,\n",
       " 736: 436,\n",
       " 737: 450,\n",
       " 738: 338,\n",
       " 739: 420,\n",
       " 740: 344,\n",
       " 741: 393,\n",
       " 742: 526,\n",
       " 743: 374,\n",
       " 744: 375,\n",
       " 745: 450,\n",
       " 746: 456,\n",
       " 747: 227,\n",
       " 748: 543,\n",
       " 749: 444,\n",
       " 750: 331,\n",
       " 751: 617,\n",
       " 752: 434,\n",
       " 753: 281,\n",
       " 754: 542,\n",
       " 755: 433,\n",
       " 756: 567,\n",
       " 757: 490,\n",
       " 758: 558,\n",
       " 759: 626,\n",
       " 760: 376,\n",
       " 761: 482,\n",
       " 762: 458,\n",
       " 763: 358,\n",
       " 764: 587,\n",
       " 765: 344,\n",
       " 766: 426,\n",
       " 767: 434,\n",
       " 768: 482,\n",
       " 769: 260,\n",
       " 770: 320,\n",
       " 771: 585,\n",
       " 772: 285,\n",
       " 773: 555,\n",
       " 774: 281,\n",
       " 775: 576,\n",
       " 776: 376,\n",
       " 777: 614,\n",
       " 778: 349,\n",
       " 779: 452,\n",
       " 780: 121,\n",
       " 781: 347,\n",
       " 782: 29,\n",
       " 783: 349,\n",
       " 784: 517,\n",
       " 785: 623,\n",
       " 786: 627,\n",
       " 787: 309,\n",
       " 788: 526,\n",
       " 789: 595,\n",
       " 790: 433,\n",
       " 791: 320,\n",
       " 792: 393,\n",
       " 793: 315,\n",
       " 794: 196,\n",
       " 795: 233,\n",
       " 796: 375,\n",
       " 797: 198,\n",
       " 798: 245,\n",
       " 799: 439,\n",
       " 800: 599,\n",
       " 801: 157,\n",
       " 802: 348,\n",
       " 803: 386,\n",
       " 804: 635,\n",
       " 805: 359,\n",
       " 806: 452,\n",
       " 807: 485,\n",
       " 808: 348,\n",
       " 809: 438,\n",
       " 810: 297,\n",
       " 811: 323,\n",
       " 812: 266,\n",
       " 813: 106,\n",
       " 814: 224,\n",
       " 815: 22,\n",
       " 816: 615,\n",
       " 817: 141,\n",
       " 818: 22,\n",
       " 819: 485,\n",
       " 820: 269,\n",
       " 821: 242,\n",
       " 822: 583,\n",
       " 823: 482,\n",
       " 824: 576,\n",
       " 825: 92,\n",
       " 826: 364,\n",
       " 827: 139,\n",
       " 828: 115,\n",
       " 829: 224,\n",
       " 830: 466,\n",
       " 831: 504,\n",
       " 832: 438,\n",
       " 833: 643,\n",
       " 834: 435,\n",
       " 835: 547,\n",
       " 836: 603,\n",
       " 837: 640,\n",
       " 838: 379,\n",
       " 839: 55,\n",
       " 840: 351,\n",
       " 841: 324,\n",
       " 842: 614,\n",
       " 843: 563,\n",
       " 844: 509,\n",
       " 845: 454,\n",
       " 846: 458,\n",
       " 847: 245,\n",
       " 848: 557,\n",
       " 849: 198,\n",
       " 850: 47,\n",
       " 851: 560,\n",
       " 852: 426,\n",
       " 853: 530,\n",
       " 854: 515,\n",
       " 855: 642,\n",
       " 856: 492,\n",
       " 857: 275,\n",
       " 858: 633,\n",
       " 859: 541,\n",
       " 860: 101,\n",
       " 861: 348,\n",
       " 862: 590,\n",
       " 863: 439,\n",
       " 864: 382,\n",
       " 865: 426,\n",
       " 866: 253,\n",
       " 867: 291,\n",
       " 868: 564,\n",
       " 869: 433,\n",
       " 870: 634,\n",
       " 871: 430,\n",
       " 872: 182,\n",
       " 873: 538,\n",
       " 874: 118,\n",
       " 875: 539,\n",
       " 876: 116,\n",
       " 877: 226,\n",
       " 878: 295,\n",
       " 879: 431,\n",
       " 880: 196,\n",
       " 881: 348,\n",
       " 882: 34,\n",
       " 883: 619,\n",
       " 884: 453,\n",
       " 885: 242,\n",
       " 886: 298,\n",
       " 887: 140,\n",
       " 888: 576,\n",
       " 889: 141,\n",
       " 890: 503,\n",
       " 891: 172,\n",
       " 892: 539,\n",
       " 893: 302,\n",
       " 894: 224,\n",
       " 895: 539,\n",
       " 896: 621,\n",
       " 897: 198,\n",
       " 898: 203,\n",
       " 899: 569,\n",
       " 900: 18,\n",
       " 901: 486,\n",
       " 902: 579,\n",
       " 903: 634,\n",
       " 904: 137,\n",
       " 905: 426,\n",
       " 906: 526,\n",
       " 907: 98,\n",
       " 908: 485,\n",
       " 909: 24,\n",
       " 910: 450,\n",
       " 911: 331,\n",
       " 912: 266,\n",
       " 913: 338,\n",
       " 914: 438,\n",
       " 915: 355,\n",
       " 916: 564,\n",
       " 917: 450,\n",
       " 918: 526,\n",
       " 919: 131,\n",
       " 920: 583,\n",
       " 921: 33,\n",
       " 922: 396,\n",
       " 923: 480,\n",
       " 924: 642,\n",
       " 925: 566,\n",
       " 926: 210,\n",
       " 927: 634,\n",
       " 928: 431,\n",
       " 929: 269,\n",
       " 930: 396,\n",
       " 931: 615,\n",
       " 932: 506,\n",
       " 933: 64,\n",
       " 934: 285,\n",
       " 935: 533,\n",
       " 936: 14,\n",
       " 937: 387,\n",
       " 938: 98,\n",
       " 939: 245,\n",
       " 940: 198,\n",
       " 941: 364,\n",
       " 942: 623,\n",
       " 943: 47,\n",
       " 944: 475,\n",
       " 945: 279,\n",
       " 946: 591,\n",
       " 947: 590,\n",
       " 948: 478,\n",
       " 949: 324,\n",
       " 950: 486,\n",
       " 951: 621,\n",
       " 952: 486,\n",
       " 953: 293,\n",
       " 954: 341,\n",
       " 955: 438,\n",
       " 956: 260,\n",
       " 957: 456,\n",
       " 958: 344,\n",
       " 959: 492,\n",
       " 960: 635,\n",
       " 961: 172,\n",
       " 962: 454,\n",
       " 963: 624,\n",
       " 964: 366,\n",
       " 965: 292,\n",
       " 966: 570,\n",
       " 967: 603,\n",
       " 968: 520,\n",
       " 969: 50,\n",
       " 970: 478,\n",
       " 971: 274,\n",
       " 972: 530,\n",
       " 973: 485,\n",
       " 974: 217,\n",
       " 975: 396,\n",
       " 976: 344,\n",
       " 977: 640,\n",
       " 978: 355,\n",
       " 979: 274,\n",
       " 980: 345,\n",
       " 981: 248,\n",
       " 982: 590,\n",
       " 983: 434,\n",
       " 984: 570,\n",
       " 985: 396,\n",
       " 986: 198,\n",
       " 987: 575,\n",
       " 988: 572,\n",
       " 989: 141,\n",
       " 990: 379,\n",
       " 991: 506,\n",
       " 992: 484,\n",
       " 993: 590,\n",
       " 994: 431,\n",
       " 995: 635,\n",
       " 996: 98,\n",
       " 997: 484,\n",
       " 998: 117,\n",
       " 999: 619,\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping each test instance to the ID of the correct answer\n",
    "import pandas as pd\n",
    "\n",
    "# Load Excel file containing ground-truth answers\n",
    "df = pd.read_excel(\"transe_true_score.xlsx\")\n",
    "\n",
    "# Build a dictionary: {row_index: correct_answer_id}\n",
    "dictrue = {index: key for index, key in zip(df.index, df['Key'])}\n",
    "\n",
    "# Print the total number of entries\n",
    "print(f\"Total entries in dictrue: {len(dictrue)}\")\n",
    "\n",
    "# Optional: display the dictionary\n",
    "dictrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb4e4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotate_true</th>\n",
       "      <th>transe_true</th>\n",
       "      <th>distmult_true</th>\n",
       "      <th>originbert_true</th>\n",
       "      <th>pubmedbert_true</th>\n",
       "      <th>biobert_true</th>\n",
       "      <th>glm2_true</th>\n",
       "      <th>glm4_true</th>\n",
       "      <th>llama3_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.257660</td>\n",
       "      <td>1.232071</td>\n",
       "      <td>1.214594</td>\n",
       "      <td>0.804364</td>\n",
       "      <td>0.911068</td>\n",
       "      <td>0.734272</td>\n",
       "      <td>1.248592</td>\n",
       "      <td>1.252768</td>\n",
       "      <td>1.252659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.038639</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.715440</td>\n",
       "      <td>0.739049</td>\n",
       "      <td>0.571880</td>\n",
       "      <td>0.673245</td>\n",
       "      <td>1.035015</td>\n",
       "      <td>1.035514</td>\n",
       "      <td>1.034725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.153540</td>\n",
       "      <td>1.135198</td>\n",
       "      <td>1.276516</td>\n",
       "      <td>0.689268</td>\n",
       "      <td>0.634991</td>\n",
       "      <td>1.060342</td>\n",
       "      <td>1.148576</td>\n",
       "      <td>1.152746</td>\n",
       "      <td>1.152657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.643458</td>\n",
       "      <td>1.355012</td>\n",
       "      <td>0.971790</td>\n",
       "      <td>1.187350</td>\n",
       "      <td>1.375415</td>\n",
       "      <td>1.340166</td>\n",
       "      <td>1.633207</td>\n",
       "      <td>1.641203</td>\n",
       "      <td>1.644143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.113442</td>\n",
       "      <td>1.539271</td>\n",
       "      <td>2.164795</td>\n",
       "      <td>2.594134</td>\n",
       "      <td>2.404367</td>\n",
       "      <td>2.466599</td>\n",
       "      <td>2.217878</td>\n",
       "      <td>2.144502</td>\n",
       "      <td>2.035953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1.296422</td>\n",
       "      <td>1.265670</td>\n",
       "      <td>1.353095</td>\n",
       "      <td>1.240062</td>\n",
       "      <td>1.432996</td>\n",
       "      <td>1.205061</td>\n",
       "      <td>1.287064</td>\n",
       "      <td>1.290892</td>\n",
       "      <td>1.290231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1.243247</td>\n",
       "      <td>1.322289</td>\n",
       "      <td>1.321946</td>\n",
       "      <td>1.087797</td>\n",
       "      <td>1.104896</td>\n",
       "      <td>0.812995</td>\n",
       "      <td>1.235773</td>\n",
       "      <td>1.243151</td>\n",
       "      <td>1.239638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1.470620</td>\n",
       "      <td>1.567364</td>\n",
       "      <td>1.668912</td>\n",
       "      <td>0.389371</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.529933</td>\n",
       "      <td>1.459554</td>\n",
       "      <td>1.465014</td>\n",
       "      <td>1.467012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1.554556</td>\n",
       "      <td>1.380122</td>\n",
       "      <td>1.240120</td>\n",
       "      <td>1.193361</td>\n",
       "      <td>1.377532</td>\n",
       "      <td>1.416225</td>\n",
       "      <td>1.527110</td>\n",
       "      <td>1.534309</td>\n",
       "      <td>1.542176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1.641920</td>\n",
       "      <td>1.323430</td>\n",
       "      <td>1.058850</td>\n",
       "      <td>1.786607</td>\n",
       "      <td>1.601692</td>\n",
       "      <td>2.040046</td>\n",
       "      <td>1.630818</td>\n",
       "      <td>1.626269</td>\n",
       "      <td>1.628353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotate_true  transe_true  distmult_true  originbert_true  \\\n",
       "0         1.257660     1.232071       1.214594         0.804364   \n",
       "1         1.038639     0.975394       0.715440         0.739049   \n",
       "2         1.153540     1.135198       1.276516         0.689268   \n",
       "3         1.643458     1.355012       0.971790         1.187350   \n",
       "4         2.113442     1.539271       2.164795         2.594134   \n",
       "...            ...          ...            ...              ...   \n",
       "99995     1.296422     1.265670       1.353095         1.240062   \n",
       "99996     1.243247     1.322289       1.321946         1.087797   \n",
       "99997     1.470620     1.567364       1.668912         0.389371   \n",
       "99998     1.554556     1.380122       1.240120         1.193361   \n",
       "99999     1.641920     1.323430       1.058850         1.786607   \n",
       "\n",
       "       pubmedbert_true  biobert_true  glm2_true  glm4_true  llama3_true  \n",
       "0             0.911068      0.734272   1.248592   1.252768     1.252659  \n",
       "1             0.571880      0.673245   1.035015   1.035514     1.034725  \n",
       "2             0.634991      1.060342   1.148576   1.152746     1.152657  \n",
       "3             1.375415      1.340166   1.633207   1.641203     1.644143  \n",
       "4             2.404367      2.466599   2.217878   2.144502     2.035953  \n",
       "...                ...           ...        ...        ...          ...  \n",
       "99995         1.432996      1.205061   1.287064   1.290892     1.290231  \n",
       "99996         1.104896      0.812995   1.235773   1.243151     1.239638  \n",
       "99997         0.697817      0.529933   1.459554   1.465014     1.467012  \n",
       "99998         1.377532      1.416225   1.527110   1.534309     1.542176  \n",
       "99999         1.601692      2.040046   1.630818   1.626269     1.628353  \n",
       "\n",
       "[100000 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract standardized scores of the correct answers from each model\n",
    "\n",
    "# Initialize a list to store the results\n",
    "result_list_true = []\n",
    "\n",
    "# Iterate over the dictrue mapping: {column_index: row_index_of_correct_answer}\n",
    "for col, row in dictrue.items():\n",
    "    # Extract the score of the correct answer from each model's standardized matrix\n",
    "    z1_value = df1_standardized.iloc[row, col]  # RotatE\n",
    "    z2_value = df2_standardized.iloc[row, col]  # TransE\n",
    "    z3_value = df3_standardized.iloc[row, col]  # DistMult\n",
    "    z4_value = df4_standardized.iloc[row, col]  # OriginBERT\n",
    "    z5_value = df5_standardized.iloc[row, col]  # PubMedBERT\n",
    "    z6_value = df6_standardized.iloc[row, col]  # BioBERT\n",
    "    z7_value = df7_standardized.iloc[row, col]  # GLM2\n",
    "    z8_value = df8_standardized.iloc[row, col]  # GLM4\n",
    "    z9_value = df9_standardized.iloc[row, col]  # LLaMA3\n",
    "\n",
    "    # Append the values to the result list\n",
    "    result_list_true.append([\n",
    "        z1_value, z2_value, z3_value,\n",
    "        z4_value, z5_value, z6_value,\n",
    "        z7_value, z8_value, z9_value\n",
    "    ])\n",
    "\n",
    "# Convert the result list to a DataFrame with appropriate column names\n",
    "result_df_true = pd.DataFrame(\n",
    "    result_list_true,\n",
    "    columns=[\n",
    "        'rotate_true', 'transe_true', 'distmult_true',\n",
    "        'originbert_true', 'pubmedbert_true', 'biobert_true',\n",
    "        'glm2_true', 'glm4_true', 'llama3_true'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "result_df_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_df_rotate:\n",
      "       rotate_max  rotate_max_index  rotate_1% quantile  rotate_1% index\n",
      "0        1.513106               526            1.390932              485\n",
      "1        1.619167               533            1.538449              485\n",
      "2        1.654554               258            1.593277              378\n",
      "3        2.184071               139            2.093694              509\n",
      "4        2.295056               395            2.151740              529\n",
      "...           ...               ...                 ...              ...\n",
      "99995    1.768962               291            1.630050              507\n",
      "99996    1.936620               642            1.843458              176\n",
      "99997    1.845040               121            1.670849              642\n",
      "99998    2.196355               485            1.893593              450\n",
      "99999    2.172254               485            1.955818              615\n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_transe:\n",
      "       transe_max  transe_max_index  transe_1% quantile  transe_1% index\n",
      "0        1.308151               450            1.260692              526\n",
      "1        1.437719               310            1.394631              482\n",
      "2        1.617004               260            1.503424              240\n",
      "3        1.683493               139            1.609475              576\n",
      "4        1.730752               548            1.584565              634\n",
      "...           ...               ...                 ...              ...\n",
      "99995    1.663762               276            1.466692              564\n",
      "99996    1.868782               599            1.749199              331\n",
      "99997    1.644984               623            1.534274              438\n",
      "99998    1.894028               485            1.613644              618\n",
      "99999    1.743960               485            1.681421              450\n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_distmult:\n",
      "       distmult_max  distmult_max_index  distmult_1% quantile  \\\n",
      "0          1.653797                 394              1.492267   \n",
      "1          1.525342                 121              1.455364   \n",
      "2          2.445789                 245              1.738411   \n",
      "3          2.073291                 456              1.793633   \n",
      "4          2.283259                 366              1.981562   \n",
      "...             ...                 ...                   ...   \n",
      "99995      2.074515                 184              1.899251   \n",
      "99996      1.996142                 532              1.922880   \n",
      "99997      2.296086                 618              2.224622   \n",
      "99998      2.175708                 642              1.844729   \n",
      "99999      1.909514                  83              1.726796   \n",
      "\n",
      "       distmult_1% index  \n",
      "0                    453  \n",
      "1                    642  \n",
      "2                    438  \n",
      "3                    348  \n",
      "4                    395  \n",
      "...                  ...  \n",
      "99995                226  \n",
      "99996                623  \n",
      "99997                438  \n",
      "99998                485  \n",
      "99999                141  \n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_originbert:\n",
      "       originbert_max  originbert_max_index  originbert_1% quantile  \\\n",
      "0            2.192274                   526                1.734806   \n",
      "1            2.583037                    21                1.778246   \n",
      "2            6.317808                   472                5.007052   \n",
      "3            2.881158                   433                2.418459   \n",
      "4            3.907130                   395                3.607017   \n",
      "...               ...                   ...                     ...   \n",
      "99995        2.557645                    47                2.197443   \n",
      "99996        2.802423                   441                2.455533   \n",
      "99997        4.172904                   502                3.339743   \n",
      "99998        3.399189                    56                2.393022   \n",
      "99999        3.212137                   450                2.293851   \n",
      "\n",
      "       originbert_1% index  \n",
      "0                      593  \n",
      "1                      510  \n",
      "2                      245  \n",
      "3                      552  \n",
      "4                      473  \n",
      "...                    ...  \n",
      "99995                  291  \n",
      "99996                  413  \n",
      "99997                  437  \n",
      "99998                  642  \n",
      "99999                  569  \n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_pubmedbert:\n",
      "       pubmedbert_max  pubmedbert_max_index  pubmedbert_1% quantile  \\\n",
      "0            1.988101                   254                1.707136   \n",
      "1            2.507792                    21                1.917054   \n",
      "2            5.987475                   472                4.660890   \n",
      "3            2.539412                   433                2.319388   \n",
      "4            3.768231                   639                3.310732   \n",
      "...               ...                   ...                     ...   \n",
      "99995        2.993004                   639                2.208593   \n",
      "99996        2.507270                   458                2.354448   \n",
      "99997        4.052426                   502                3.469406   \n",
      "99998        3.449386                    56                2.130933   \n",
      "99999        2.485319                   450                2.016612   \n",
      "\n",
      "       pubmedbert_1% index  \n",
      "0                        9  \n",
      "1                      510  \n",
      "2                      374  \n",
      "3                      358  \n",
      "4                      623  \n",
      "...                    ...  \n",
      "99995                  563  \n",
      "99996                  636  \n",
      "99997                  164  \n",
      "99998                  485  \n",
      "99999                  569  \n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_biobert:\n",
      "       biobert_max  biobert_max_index  biobert_1% quantile  biobert_1% index\n",
      "0         2.207962                579             1.705254               526\n",
      "1         2.513620                 21             1.707564               546\n",
      "2         5.691224                472             4.173824               435\n",
      "3         2.828675                 75             2.332505                22\n",
      "4         3.360302                473             3.217942               566\n",
      "...            ...                ...                  ...               ...\n",
      "99995     2.480423                289             2.095062               603\n",
      "99996     2.824764                458             2.489469               599\n",
      "99997     4.019795                502             3.484985               198\n",
      "99998     2.953459                159             2.241294               141\n",
      "99999     2.660994                450             2.023918               515\n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_glm2:\n",
      "       glm2_max  glm2_max_index  glm2_1% quantile  glm2_1% index\n",
      "0      1.502856             485          1.499301            623\n",
      "1      1.614294             485          1.592052            533\n",
      "2      1.648204             485          1.638904            331\n",
      "3      2.171221             526          2.154002            634\n",
      "4      2.274379             642          2.244325            395\n",
      "...         ...             ...               ...            ...\n",
      "99995  1.757271             599          1.738149            615\n",
      "99996  1.926239             642          1.915930            599\n",
      "99997  1.831958             485          1.810228            618\n",
      "99998  2.160367             642          2.110858            599\n",
      "99999  2.158408             642          2.081883            438\n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_glm4:\n",
      "       glm4_max  glm4_max_index  glm4_1% quantile  glm4_1% index\n",
      "0      1.507580             450          1.464716            623\n",
      "1      1.614966             526          1.582954            458\n",
      "2      1.653544             438          1.583500            260\n",
      "3      2.181244             526          2.128178            538\n",
      "4      2.287868             543          2.193656            596\n",
      "...         ...             ...               ...            ...\n",
      "99995  1.762060             526          1.694635            552\n",
      "99996  1.936483             450          1.873320            569\n",
      "99997  1.838415             642          1.769395            569\n",
      "99998  2.169821             450          2.109294            642\n",
      "99999  2.152734             526          2.121268            485\n",
      "\n",
      "[100000 rows x 4 columns]\n",
      "summary_df_llama3:\n",
      "       llama3_max  llama3_max_index  llama3_1% quantile  llama3_1% index\n",
      "0        1.507457               485            1.453461              623\n",
      "1        1.613907               485            1.580693              520\n",
      "2        1.653429               485            1.592689              260\n",
      "3        2.184941               619            2.048337              576\n",
      "4        2.290736                22            2.148296              552\n",
      "...           ...               ...                 ...              ...\n",
      "99995    1.761235               396            1.703596              450\n",
      "99996    1.931613               348            1.889454              450\n",
      "99997    1.840780               485            1.725278              491\n",
      "99998    2.180154               485            2.019140              245\n",
      "99999    2.155340               438            2.060633              599\n",
      "\n",
      "[100000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract maximum z-score and 1% quantile features\n",
    "# Assume df1_standardized, df2_standardized, ..., df9_standardized are the standardized matrices\n",
    "# These copies will be used to mask the ground-truth positions with NaN\n",
    "df1_standardized_copy = df1_standardized.copy()\n",
    "df2_standardized_copy = df2_standardized.copy()\n",
    "df3_standardized_copy = df3_standardized.copy()\n",
    "df4_standardized_copy = df4_standardized.copy()\n",
    "df5_standardized_copy = df5_standardized.copy()\n",
    "df6_standardized_copy = df6_standardized.copy()\n",
    "df7_standardized_copy = df7_standardized.copy()\n",
    "df8_standardized_copy = df8_standardized.copy()\n",
    "df9_standardized_copy = df9_standardized.copy()\n",
    "\n",
    "# Mask the true answer positions with NaN\n",
    "for i, row_index in dictrue.items():\n",
    "    df1_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df2_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df3_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df4_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df5_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df6_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df7_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df8_standardized_copy.iloc[row_index, i] = np.nan\n",
    "    df9_standardized_copy.iloc[row_index, i] = np.nan\n",
    "\n",
    "# List of all model score matrices and their method names\n",
    "dfs = [\n",
    "    df1_standardized_copy, df2_standardized_copy, df3_standardized_copy,\n",
    "    df4_standardized_copy, df5_standardized_copy, df6_standardized_copy,\n",
    "    df7_standardized_copy, df8_standardized_copy, df9_standardized_copy\n",
    "]\n",
    "method_names = [\n",
    "    'rotate', 'transe', 'distmult',\n",
    "    'originbert', 'pubmedbert', 'biobert',\n",
    "    'glm2', 'glm4', 'llama3'\n",
    "]\n",
    "\n",
    "# List to store the final summary DataFrames for each method\n",
    "summary_dfs = []\n",
    "\n",
    "for df, method in zip(dfs, method_names):\n",
    "    # Compute max and second max values (excluding the ground-truth which is masked)\n",
    "    max_values = {}\n",
    "    second_max_values = {}\n",
    "    max_indices = {}\n",
    "    second_max_indices = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        top_2_values = df[col].nlargest(2)\n",
    "        max_values[col] = top_2_values.iloc[0]\n",
    "        max_indices[col] = top_2_values.index[0]\n",
    "        second_max_values[col] = top_2_values.iloc[1]\n",
    "        second_max_indices[col] = top_2_values.index[1]\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'max_value': pd.Series(max_values),\n",
    "        'max_index': pd.Series(max_indices),\n",
    "        'second_max_value': pd.Series(second_max_values),\n",
    "        'second_max_index': pd.Series(second_max_indices)\n",
    "    })\n",
    "\n",
    "    # Create final max feature based on whether the top prediction is correct (optional logic)\n",
    "    new_result_list = []\n",
    "    for col in range(len(result_df)):\n",
    "        max_index = result_df['max_index'].iloc[col]\n",
    "        new_result_list.append((result_df['max_value'].iloc[col], max_index))\n",
    "\n",
    "    new_result_df = pd.DataFrame(\n",
    "        new_result_list,\n",
    "        columns=[f'{method}_max', f'{method}_max_index']\n",
    "    )\n",
    "\n",
    "    # Compute 1% quantile value and its index for each column\n",
    "    pct1_values = []\n",
    "    pct1_indices = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        n = max(int(len(df) * 0.01), 1)  # Ensure at least one value\n",
    "        top_1_percent_values = df[col].nlargest(n)\n",
    "        pct1_values.append(top_1_percent_values.iloc[-1])\n",
    "        pct1_indices.append(top_1_percent_values.index[-1])\n",
    "\n",
    "    pct1_df = pd.DataFrame({\n",
    "        f'{method}_1pct_value': pct1_values,\n",
    "        f'{method}_1pct_index': pct1_indices\n",
    "    })\n",
    "\n",
    "    # Merge max and quantile features\n",
    "    summary_df = pd.concat([new_result_df, pct1_df], axis=1)\n",
    "    summary_dfs.append(summary_df)\n",
    "\n",
    "# Optional: print each summary DataFrame for inspection\n",
    "for i, summary_df in enumerate(summary_dfs, 1):\n",
    "    print(f\"summary_df_{method_names[i-1]}:\")\n",
    "    print(summary_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74fee22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df_rotate = summary_dfs[0]  # rotate\n",
    "summary_df_transe = summary_dfs[1]  # transe\n",
    "summary_df_distmult = summary_dfs[2]  # distmult\n",
    "summary_df_originbert = summary_dfs[3]  # originbert\n",
    "summary_df_pubmedbert = summary_dfs[4]  # pubmedbert\n",
    "summary_df_biobert = summary_dfs[5]  # biobert\n",
    "summary_df_glm2 = summary_dfs[6]  # glm2prob\n",
    "summary_df_glm4 = summary_dfs[7]  # biobert\n",
    "summary_df_llama3 = summary_dfs[8]  # glm2prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad39ff26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biobert_max</th>\n",
       "      <th>biobert_max_index</th>\n",
       "      <th>biobert_1% quantile</th>\n",
       "      <th>biobert_1% index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.207962</td>\n",
       "      <td>579</td>\n",
       "      <td>1.705254</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.513620</td>\n",
       "      <td>21</td>\n",
       "      <td>1.707564</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.691224</td>\n",
       "      <td>472</td>\n",
       "      <td>4.173824</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.828675</td>\n",
       "      <td>75</td>\n",
       "      <td>2.332505</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.360302</td>\n",
       "      <td>473</td>\n",
       "      <td>3.217942</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2.480423</td>\n",
       "      <td>289</td>\n",
       "      <td>2.095062</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2.824764</td>\n",
       "      <td>458</td>\n",
       "      <td>2.489469</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>4.019795</td>\n",
       "      <td>502</td>\n",
       "      <td>3.484985</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2.953459</td>\n",
       "      <td>159</td>\n",
       "      <td>2.241294</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2.660994</td>\n",
       "      <td>450</td>\n",
       "      <td>2.023918</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       biobert_max  biobert_max_index  biobert_1% quantile  biobert_1% index\n",
       "0         2.207962                579             1.705254               526\n",
       "1         2.513620                 21             1.707564               546\n",
       "2         5.691224                472             4.173824               435\n",
       "3         2.828675                 75             2.332505                22\n",
       "4         3.360302                473             3.217942               566\n",
       "...            ...                ...                  ...               ...\n",
       "99995     2.480423                289             2.095062               603\n",
       "99996     2.824764                458             2.489469               599\n",
       "99997     4.019795                502             3.484985               198\n",
       "99998     2.953459                159             2.241294               141\n",
       "99999     2.660994                450             2.023918               515\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df_biobert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd22f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotate_true</th>\n",
       "      <th>transe_true</th>\n",
       "      <th>distmult_true</th>\n",
       "      <th>originbert_true</th>\n",
       "      <th>pubmedbert_true</th>\n",
       "      <th>biobert_true</th>\n",
       "      <th>glm2_true</th>\n",
       "      <th>glm4_true</th>\n",
       "      <th>llama3_true</th>\n",
       "      <th>rotate_max</th>\n",
       "      <th>...</th>\n",
       "      <th>glm2_1% quantile</th>\n",
       "      <th>glm2_1% index</th>\n",
       "      <th>glm4_max</th>\n",
       "      <th>glm4_max_index</th>\n",
       "      <th>glm4_1% quantile</th>\n",
       "      <th>glm4_1% index</th>\n",
       "      <th>llama3_max</th>\n",
       "      <th>llama3_max_index</th>\n",
       "      <th>llama3_1% quantile</th>\n",
       "      <th>llama3_1% index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.257660</td>\n",
       "      <td>1.232071</td>\n",
       "      <td>1.214594</td>\n",
       "      <td>0.804364</td>\n",
       "      <td>0.911068</td>\n",
       "      <td>0.734272</td>\n",
       "      <td>1.248592</td>\n",
       "      <td>1.252768</td>\n",
       "      <td>1.252659</td>\n",
       "      <td>1.513106</td>\n",
       "      <td>...</td>\n",
       "      <td>1.499301</td>\n",
       "      <td>623</td>\n",
       "      <td>1.507580</td>\n",
       "      <td>450</td>\n",
       "      <td>1.464716</td>\n",
       "      <td>623</td>\n",
       "      <td>1.507457</td>\n",
       "      <td>485</td>\n",
       "      <td>1.453461</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.038639</td>\n",
       "      <td>0.975394</td>\n",
       "      <td>0.715440</td>\n",
       "      <td>0.739049</td>\n",
       "      <td>0.571880</td>\n",
       "      <td>0.673245</td>\n",
       "      <td>1.035015</td>\n",
       "      <td>1.035514</td>\n",
       "      <td>1.034725</td>\n",
       "      <td>1.619167</td>\n",
       "      <td>...</td>\n",
       "      <td>1.592052</td>\n",
       "      <td>533</td>\n",
       "      <td>1.614966</td>\n",
       "      <td>526</td>\n",
       "      <td>1.582954</td>\n",
       "      <td>458</td>\n",
       "      <td>1.613907</td>\n",
       "      <td>485</td>\n",
       "      <td>1.580693</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.153540</td>\n",
       "      <td>1.135198</td>\n",
       "      <td>1.276516</td>\n",
       "      <td>0.689268</td>\n",
       "      <td>0.634991</td>\n",
       "      <td>1.060342</td>\n",
       "      <td>1.148576</td>\n",
       "      <td>1.152746</td>\n",
       "      <td>1.152657</td>\n",
       "      <td>1.654554</td>\n",
       "      <td>...</td>\n",
       "      <td>1.638904</td>\n",
       "      <td>331</td>\n",
       "      <td>1.653544</td>\n",
       "      <td>438</td>\n",
       "      <td>1.583500</td>\n",
       "      <td>260</td>\n",
       "      <td>1.653429</td>\n",
       "      <td>485</td>\n",
       "      <td>1.592689</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.643458</td>\n",
       "      <td>1.355012</td>\n",
       "      <td>0.971790</td>\n",
       "      <td>1.187350</td>\n",
       "      <td>1.375415</td>\n",
       "      <td>1.340166</td>\n",
       "      <td>1.633207</td>\n",
       "      <td>1.641203</td>\n",
       "      <td>1.644143</td>\n",
       "      <td>2.184071</td>\n",
       "      <td>...</td>\n",
       "      <td>2.154002</td>\n",
       "      <td>634</td>\n",
       "      <td>2.181244</td>\n",
       "      <td>526</td>\n",
       "      <td>2.128178</td>\n",
       "      <td>538</td>\n",
       "      <td>2.184941</td>\n",
       "      <td>619</td>\n",
       "      <td>2.048337</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.113442</td>\n",
       "      <td>1.539271</td>\n",
       "      <td>2.164795</td>\n",
       "      <td>2.594134</td>\n",
       "      <td>2.404367</td>\n",
       "      <td>2.466599</td>\n",
       "      <td>2.217878</td>\n",
       "      <td>2.144502</td>\n",
       "      <td>2.035953</td>\n",
       "      <td>2.295056</td>\n",
       "      <td>...</td>\n",
       "      <td>2.244325</td>\n",
       "      <td>395</td>\n",
       "      <td>2.287868</td>\n",
       "      <td>543</td>\n",
       "      <td>2.193656</td>\n",
       "      <td>596</td>\n",
       "      <td>2.290736</td>\n",
       "      <td>22</td>\n",
       "      <td>2.148296</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>1.296422</td>\n",
       "      <td>1.265670</td>\n",
       "      <td>1.353095</td>\n",
       "      <td>1.240062</td>\n",
       "      <td>1.432996</td>\n",
       "      <td>1.205061</td>\n",
       "      <td>1.287064</td>\n",
       "      <td>1.290892</td>\n",
       "      <td>1.290231</td>\n",
       "      <td>1.768962</td>\n",
       "      <td>...</td>\n",
       "      <td>1.738149</td>\n",
       "      <td>615</td>\n",
       "      <td>1.762060</td>\n",
       "      <td>526</td>\n",
       "      <td>1.694635</td>\n",
       "      <td>552</td>\n",
       "      <td>1.761235</td>\n",
       "      <td>396</td>\n",
       "      <td>1.703596</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1.243247</td>\n",
       "      <td>1.322289</td>\n",
       "      <td>1.321946</td>\n",
       "      <td>1.087797</td>\n",
       "      <td>1.104896</td>\n",
       "      <td>0.812995</td>\n",
       "      <td>1.235773</td>\n",
       "      <td>1.243151</td>\n",
       "      <td>1.239638</td>\n",
       "      <td>1.936620</td>\n",
       "      <td>...</td>\n",
       "      <td>1.915930</td>\n",
       "      <td>599</td>\n",
       "      <td>1.936483</td>\n",
       "      <td>450</td>\n",
       "      <td>1.873320</td>\n",
       "      <td>569</td>\n",
       "      <td>1.931613</td>\n",
       "      <td>348</td>\n",
       "      <td>1.889454</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1.470620</td>\n",
       "      <td>1.567364</td>\n",
       "      <td>1.668912</td>\n",
       "      <td>0.389371</td>\n",
       "      <td>0.697817</td>\n",
       "      <td>0.529933</td>\n",
       "      <td>1.459554</td>\n",
       "      <td>1.465014</td>\n",
       "      <td>1.467012</td>\n",
       "      <td>1.845040</td>\n",
       "      <td>...</td>\n",
       "      <td>1.810228</td>\n",
       "      <td>618</td>\n",
       "      <td>1.838415</td>\n",
       "      <td>642</td>\n",
       "      <td>1.769395</td>\n",
       "      <td>569</td>\n",
       "      <td>1.840780</td>\n",
       "      <td>485</td>\n",
       "      <td>1.725278</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>1.554556</td>\n",
       "      <td>1.380122</td>\n",
       "      <td>1.240120</td>\n",
       "      <td>1.193361</td>\n",
       "      <td>1.377532</td>\n",
       "      <td>1.416225</td>\n",
       "      <td>1.527110</td>\n",
       "      <td>1.534309</td>\n",
       "      <td>1.542176</td>\n",
       "      <td>2.196355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.110858</td>\n",
       "      <td>599</td>\n",
       "      <td>2.169821</td>\n",
       "      <td>450</td>\n",
       "      <td>2.109294</td>\n",
       "      <td>642</td>\n",
       "      <td>2.180154</td>\n",
       "      <td>485</td>\n",
       "      <td>2.019140</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1.641920</td>\n",
       "      <td>1.323430</td>\n",
       "      <td>1.058850</td>\n",
       "      <td>1.786607</td>\n",
       "      <td>1.601692</td>\n",
       "      <td>2.040046</td>\n",
       "      <td>1.630818</td>\n",
       "      <td>1.626269</td>\n",
       "      <td>1.628353</td>\n",
       "      <td>2.172254</td>\n",
       "      <td>...</td>\n",
       "      <td>2.081883</td>\n",
       "      <td>438</td>\n",
       "      <td>2.152734</td>\n",
       "      <td>526</td>\n",
       "      <td>2.121268</td>\n",
       "      <td>485</td>\n",
       "      <td>2.155340</td>\n",
       "      <td>438</td>\n",
       "      <td>2.060633</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotate_true  transe_true  distmult_true  originbert_true  \\\n",
       "0         1.257660     1.232071       1.214594         0.804364   \n",
       "1         1.038639     0.975394       0.715440         0.739049   \n",
       "2         1.153540     1.135198       1.276516         0.689268   \n",
       "3         1.643458     1.355012       0.971790         1.187350   \n",
       "4         2.113442     1.539271       2.164795         2.594134   \n",
       "...            ...          ...            ...              ...   \n",
       "99995     1.296422     1.265670       1.353095         1.240062   \n",
       "99996     1.243247     1.322289       1.321946         1.087797   \n",
       "99997     1.470620     1.567364       1.668912         0.389371   \n",
       "99998     1.554556     1.380122       1.240120         1.193361   \n",
       "99999     1.641920     1.323430       1.058850         1.786607   \n",
       "\n",
       "       pubmedbert_true  biobert_true  glm2_true  glm4_true  llama3_true  \\\n",
       "0             0.911068      0.734272   1.248592   1.252768     1.252659   \n",
       "1             0.571880      0.673245   1.035015   1.035514     1.034725   \n",
       "2             0.634991      1.060342   1.148576   1.152746     1.152657   \n",
       "3             1.375415      1.340166   1.633207   1.641203     1.644143   \n",
       "4             2.404367      2.466599   2.217878   2.144502     2.035953   \n",
       "...                ...           ...        ...        ...          ...   \n",
       "99995         1.432996      1.205061   1.287064   1.290892     1.290231   \n",
       "99996         1.104896      0.812995   1.235773   1.243151     1.239638   \n",
       "99997         0.697817      0.529933   1.459554   1.465014     1.467012   \n",
       "99998         1.377532      1.416225   1.527110   1.534309     1.542176   \n",
       "99999         1.601692      2.040046   1.630818   1.626269     1.628353   \n",
       "\n",
       "       rotate_max  ...  glm2_1% quantile  glm2_1% index  glm4_max  \\\n",
       "0        1.513106  ...          1.499301            623  1.507580   \n",
       "1        1.619167  ...          1.592052            533  1.614966   \n",
       "2        1.654554  ...          1.638904            331  1.653544   \n",
       "3        2.184071  ...          2.154002            634  2.181244   \n",
       "4        2.295056  ...          2.244325            395  2.287868   \n",
       "...           ...  ...               ...            ...       ...   \n",
       "99995    1.768962  ...          1.738149            615  1.762060   \n",
       "99996    1.936620  ...          1.915930            599  1.936483   \n",
       "99997    1.845040  ...          1.810228            618  1.838415   \n",
       "99998    2.196355  ...          2.110858            599  2.169821   \n",
       "99999    2.172254  ...          2.081883            438  2.152734   \n",
       "\n",
       "       glm4_max_index  glm4_1% quantile  glm4_1% index  llama3_max  \\\n",
       "0                 450          1.464716            623    1.507457   \n",
       "1                 526          1.582954            458    1.613907   \n",
       "2                 438          1.583500            260    1.653429   \n",
       "3                 526          2.128178            538    2.184941   \n",
       "4                 543          2.193656            596    2.290736   \n",
       "...               ...               ...            ...         ...   \n",
       "99995             526          1.694635            552    1.761235   \n",
       "99996             450          1.873320            569    1.931613   \n",
       "99997             642          1.769395            569    1.840780   \n",
       "99998             450          2.109294            642    2.180154   \n",
       "99999             526          2.121268            485    2.155340   \n",
       "\n",
       "       llama3_max_index  llama3_1% quantile  llama3_1% index  \n",
       "0                   485            1.453461              623  \n",
       "1                   485            1.580693              520  \n",
       "2                   485            1.592689              260  \n",
       "3                   619            2.048337              576  \n",
       "4                    22            2.148296              552  \n",
       "...                 ...                 ...              ...  \n",
       "99995               396            1.703596              450  \n",
       "99996               348            1.889454              450  \n",
       "99997               485            1.725278              491  \n",
       "99998               485            2.019140              245  \n",
       "99999               438            2.060633              599  \n",
       "\n",
       "[100000 rows x 45 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all dataframes column-wise\n",
    "# The \"max\" here means: if the correct answer is ranked 1st, take the 2nd highest;\n",
    "# otherwise, take the 1st highest value.\n",
    "combined_df = pd.concat([\n",
    "    result_df_true,\n",
    "    summary_df_rotate,\n",
    "    summary_df_transe,\n",
    "    summary_df_distmult,\n",
    "    summary_df_originbert,\n",
    "    summary_df_pubmedbert,\n",
    "    summary_df_biobert,\n",
    "    summary_df_glm2,\n",
    "    summary_df_glm4,\n",
    "    summary_df_llama3\n",
    "], axis=1)\n",
    "\n",
    "# Specify output filename\n",
    "output_file = 'combined_df(Max+1Percentile).csv'\n",
    "\n",
    "# Export as CSV file\n",
    "combined_df.to_csv(output_file, index=False)  # index=False avoids saving row indices\n",
    "\n",
    "print(f\"Data has been exported to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ca938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_index</th>\n",
       "      <th>rotate_max_index</th>\n",
       "      <th>rotate_1% index</th>\n",
       "      <th>transe_max_index</th>\n",
       "      <th>transe_1% index</th>\n",
       "      <th>distmult_max_index</th>\n",
       "      <th>distmult_1% index</th>\n",
       "      <th>originbert_max_index</th>\n",
       "      <th>originbert_1% index</th>\n",
       "      <th>pubmedbert_max_index</th>\n",
       "      <th>pubmedbert_1% index</th>\n",
       "      <th>biobert_max_index</th>\n",
       "      <th>biobert_1% index</th>\n",
       "      <th>glm2_max_index</th>\n",
       "      <th>glm2_1% index</th>\n",
       "      <th>glm4_max_index</th>\n",
       "      <th>glm4_1% index</th>\n",
       "      <th>llama3_max_index</th>\n",
       "      <th>llama3_1% index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576</td>\n",
       "      <td>526</td>\n",
       "      <td>485</td>\n",
       "      <td>450</td>\n",
       "      <td>526</td>\n",
       "      <td>394</td>\n",
       "      <td>453</td>\n",
       "      <td>526</td>\n",
       "      <td>593</td>\n",
       "      <td>254</td>\n",
       "      <td>9</td>\n",
       "      <td>579</td>\n",
       "      <td>526</td>\n",
       "      <td>485</td>\n",
       "      <td>623</td>\n",
       "      <td>450</td>\n",
       "      <td>623</td>\n",
       "      <td>485</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346</td>\n",
       "      <td>533</td>\n",
       "      <td>485</td>\n",
       "      <td>310</td>\n",
       "      <td>482</td>\n",
       "      <td>121</td>\n",
       "      <td>642</td>\n",
       "      <td>21</td>\n",
       "      <td>510</td>\n",
       "      <td>21</td>\n",
       "      <td>510</td>\n",
       "      <td>21</td>\n",
       "      <td>546</td>\n",
       "      <td>485</td>\n",
       "      <td>533</td>\n",
       "      <td>526</td>\n",
       "      <td>458</td>\n",
       "      <td>485</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>520</td>\n",
       "      <td>258</td>\n",
       "      <td>378</td>\n",
       "      <td>260</td>\n",
       "      <td>240</td>\n",
       "      <td>245</td>\n",
       "      <td>438</td>\n",
       "      <td>472</td>\n",
       "      <td>245</td>\n",
       "      <td>472</td>\n",
       "      <td>374</td>\n",
       "      <td>472</td>\n",
       "      <td>435</td>\n",
       "      <td>485</td>\n",
       "      <td>331</td>\n",
       "      <td>438</td>\n",
       "      <td>260</td>\n",
       "      <td>485</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>224</td>\n",
       "      <td>139</td>\n",
       "      <td>509</td>\n",
       "      <td>139</td>\n",
       "      <td>576</td>\n",
       "      <td>456</td>\n",
       "      <td>348</td>\n",
       "      <td>433</td>\n",
       "      <td>552</td>\n",
       "      <td>433</td>\n",
       "      <td>358</td>\n",
       "      <td>75</td>\n",
       "      <td>22</td>\n",
       "      <td>526</td>\n",
       "      <td>634</td>\n",
       "      <td>526</td>\n",
       "      <td>538</td>\n",
       "      <td>619</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>618</td>\n",
       "      <td>395</td>\n",
       "      <td>529</td>\n",
       "      <td>548</td>\n",
       "      <td>634</td>\n",
       "      <td>366</td>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "      <td>473</td>\n",
       "      <td>639</td>\n",
       "      <td>623</td>\n",
       "      <td>473</td>\n",
       "      <td>566</td>\n",
       "      <td>642</td>\n",
       "      <td>395</td>\n",
       "      <td>543</td>\n",
       "      <td>596</td>\n",
       "      <td>22</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>495</td>\n",
       "      <td>291</td>\n",
       "      <td>507</td>\n",
       "      <td>276</td>\n",
       "      <td>564</td>\n",
       "      <td>184</td>\n",
       "      <td>226</td>\n",
       "      <td>47</td>\n",
       "      <td>291</td>\n",
       "      <td>639</td>\n",
       "      <td>563</td>\n",
       "      <td>289</td>\n",
       "      <td>603</td>\n",
       "      <td>599</td>\n",
       "      <td>615</td>\n",
       "      <td>526</td>\n",
       "      <td>552</td>\n",
       "      <td>396</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>506</td>\n",
       "      <td>642</td>\n",
       "      <td>176</td>\n",
       "      <td>599</td>\n",
       "      <td>331</td>\n",
       "      <td>532</td>\n",
       "      <td>623</td>\n",
       "      <td>441</td>\n",
       "      <td>413</td>\n",
       "      <td>458</td>\n",
       "      <td>636</td>\n",
       "      <td>458</td>\n",
       "      <td>599</td>\n",
       "      <td>642</td>\n",
       "      <td>599</td>\n",
       "      <td>450</td>\n",
       "      <td>569</td>\n",
       "      <td>348</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>331</td>\n",
       "      <td>121</td>\n",
       "      <td>642</td>\n",
       "      <td>623</td>\n",
       "      <td>438</td>\n",
       "      <td>618</td>\n",
       "      <td>438</td>\n",
       "      <td>502</td>\n",
       "      <td>437</td>\n",
       "      <td>502</td>\n",
       "      <td>164</td>\n",
       "      <td>502</td>\n",
       "      <td>198</td>\n",
       "      <td>485</td>\n",
       "      <td>618</td>\n",
       "      <td>642</td>\n",
       "      <td>569</td>\n",
       "      <td>485</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>426</td>\n",
       "      <td>485</td>\n",
       "      <td>450</td>\n",
       "      <td>485</td>\n",
       "      <td>618</td>\n",
       "      <td>642</td>\n",
       "      <td>485</td>\n",
       "      <td>56</td>\n",
       "      <td>642</td>\n",
       "      <td>56</td>\n",
       "      <td>485</td>\n",
       "      <td>159</td>\n",
       "      <td>141</td>\n",
       "      <td>642</td>\n",
       "      <td>599</td>\n",
       "      <td>450</td>\n",
       "      <td>642</td>\n",
       "      <td>485</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>441</td>\n",
       "      <td>485</td>\n",
       "      <td>615</td>\n",
       "      <td>485</td>\n",
       "      <td>450</td>\n",
       "      <td>83</td>\n",
       "      <td>141</td>\n",
       "      <td>450</td>\n",
       "      <td>569</td>\n",
       "      <td>450</td>\n",
       "      <td>569</td>\n",
       "      <td>450</td>\n",
       "      <td>515</td>\n",
       "      <td>642</td>\n",
       "      <td>438</td>\n",
       "      <td>526</td>\n",
       "      <td>485</td>\n",
       "      <td>438</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       true_index  rotate_max_index  rotate_1% index  transe_max_index  \\\n",
       "0             576               526              485               450   \n",
       "1             346               533              485               310   \n",
       "2             520               258              378               260   \n",
       "3             224               139              509               139   \n",
       "4             618               395              529               548   \n",
       "...           ...               ...              ...               ...   \n",
       "99995         495               291              507               276   \n",
       "99996         506               642              176               599   \n",
       "99997         331               121              642               623   \n",
       "99998         426               485              450               485   \n",
       "99999         441               485              615               485   \n",
       "\n",
       "       transe_1% index  distmult_max_index  distmult_1% index  \\\n",
       "0                  526                 394                453   \n",
       "1                  482                 121                642   \n",
       "2                  240                 245                438   \n",
       "3                  576                 456                348   \n",
       "4                  634                 366                395   \n",
       "...                ...                 ...                ...   \n",
       "99995              564                 184                226   \n",
       "99996              331                 532                623   \n",
       "99997              438                 618                438   \n",
       "99998              618                 642                485   \n",
       "99999              450                  83                141   \n",
       "\n",
       "       originbert_max_index  originbert_1% index  pubmedbert_max_index  \\\n",
       "0                       526                  593                   254   \n",
       "1                        21                  510                    21   \n",
       "2                       472                  245                   472   \n",
       "3                       433                  552                   433   \n",
       "4                       395                  473                   639   \n",
       "...                     ...                  ...                   ...   \n",
       "99995                    47                  291                   639   \n",
       "99996                   441                  413                   458   \n",
       "99997                   502                  437                   502   \n",
       "99998                    56                  642                    56   \n",
       "99999                   450                  569                   450   \n",
       "\n",
       "       pubmedbert_1% index  biobert_max_index  biobert_1% index  \\\n",
       "0                        9                579               526   \n",
       "1                      510                 21               546   \n",
       "2                      374                472               435   \n",
       "3                      358                 75                22   \n",
       "4                      623                473               566   \n",
       "...                    ...                ...               ...   \n",
       "99995                  563                289               603   \n",
       "99996                  636                458               599   \n",
       "99997                  164                502               198   \n",
       "99998                  485                159               141   \n",
       "99999                  569                450               515   \n",
       "\n",
       "       glm2_max_index  glm2_1% index  glm4_max_index  glm4_1% index  \\\n",
       "0                 485            623             450            623   \n",
       "1                 485            533             526            458   \n",
       "2                 485            331             438            260   \n",
       "3                 526            634             526            538   \n",
       "4                 642            395             543            596   \n",
       "...               ...            ...             ...            ...   \n",
       "99995             599            615             526            552   \n",
       "99996             642            599             450            569   \n",
       "99997             485            618             642            569   \n",
       "99998             642            599             450            642   \n",
       "99999             642            438             526            485   \n",
       "\n",
       "       llama3_max_index  llama3_1% index  \n",
       "0                   485              623  \n",
       "1                   485              520  \n",
       "2                   485              260  \n",
       "3                   619              576  \n",
       "4                    22              552  \n",
       "...                 ...              ...  \n",
       "99995               396              450  \n",
       "99996               348              450  \n",
       "99997               485              491  \n",
       "99998               485              245  \n",
       "99999               438              599  \n",
       "\n",
       "[100000 rows x 19 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume combined_df is the original DataFrame\n",
    "\n",
    "# Extract the 'true_index' from the dictrue dictionary\n",
    "dictrue_df = pd.DataFrame(list(dictrue.values()), columns=['true_index'])\n",
    "\n",
    "# Extract all model max index and 1% quantile index columns\n",
    "index_df = combined_df[[\n",
    "    'rotate_max_index', 'rotate_1% index',\n",
    "    'transe_max_index', 'transe_1% index',\n",
    "    'distmult_max_index', 'distmult_1% index',\n",
    "    'originbert_max_index', 'originbert_1% index',\n",
    "    'pubmedbert_max_index', 'pubmedbert_1% index',\n",
    "    'biobert_max_index', 'biobert_1% index',\n",
    "    'glm2_max_index', 'glm2_1% index',\n",
    "    'glm4_max_index', 'glm4_1% index',\n",
    "    'llama3_max_index', 'llama3_1% index'\n",
    "]]\n",
    "\n",
    "# Concatenate the true index column with the extracted index columns\n",
    "index_df = pd.concat([dictrue_df, index_df], axis=1)\n",
    "\n",
    "# Display the new DataFrame\n",
    "index_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8d082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotate_value</th>\n",
       "      <th>transe_value</th>\n",
       "      <th>distmult_value</th>\n",
       "      <th>originbert_value</th>\n",
       "      <th>pubmedbert_value</th>\n",
       "      <th>biobert_value</th>\n",
       "      <th>glm2_value</th>\n",
       "      <th>glm4_value</th>\n",
       "      <th>llama3_value</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.257660</td>\n",
       "      <td>1.232071</td>\n",
       "      <td>1.214594</td>\n",
       "      <td>0.804364</td>\n",
       "      <td>0.911068</td>\n",
       "      <td>0.734272</td>\n",
       "      <td>1.248592</td>\n",
       "      <td>1.252768</td>\n",
       "      <td>1.252659</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.513106</td>\n",
       "      <td>1.260692</td>\n",
       "      <td>1.624731</td>\n",
       "      <td>2.192274</td>\n",
       "      <td>1.666998</td>\n",
       "      <td>1.705254</td>\n",
       "      <td>1.499834</td>\n",
       "      <td>1.493802</td>\n",
       "      <td>1.421188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.390932</td>\n",
       "      <td>1.252307</td>\n",
       "      <td>1.328832</td>\n",
       "      <td>0.626029</td>\n",
       "      <td>0.549827</td>\n",
       "      <td>0.445043</td>\n",
       "      <td>1.502856</td>\n",
       "      <td>1.431038</td>\n",
       "      <td>1.507457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.364900</td>\n",
       "      <td>1.308151</td>\n",
       "      <td>0.314748</td>\n",
       "      <td>-0.257891</td>\n",
       "      <td>0.335758</td>\n",
       "      <td>-0.043891</td>\n",
       "      <td>1.491835</td>\n",
       "      <td>1.507580</td>\n",
       "      <td>1.506920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.513106</td>\n",
       "      <td>1.260692</td>\n",
       "      <td>1.624731</td>\n",
       "      <td>2.192274</td>\n",
       "      <td>1.666998</td>\n",
       "      <td>1.705254</td>\n",
       "      <td>1.499834</td>\n",
       "      <td>1.493802</td>\n",
       "      <td>1.421188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899995</th>\n",
       "      <td>1.845025</td>\n",
       "      <td>1.490592</td>\n",
       "      <td>1.072970</td>\n",
       "      <td>1.314346</td>\n",
       "      <td>1.063831</td>\n",
       "      <td>1.161041</td>\n",
       "      <td>2.081883</td>\n",
       "      <td>2.143744</td>\n",
       "      <td>2.155340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899996</th>\n",
       "      <td>1.845025</td>\n",
       "      <td>1.720561</td>\n",
       "      <td>1.412775</td>\n",
       "      <td>1.961519</td>\n",
       "      <td>1.555589</td>\n",
       "      <td>1.677154</td>\n",
       "      <td>2.090156</td>\n",
       "      <td>2.152734</td>\n",
       "      <td>2.025906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899997</th>\n",
       "      <td>2.172254</td>\n",
       "      <td>1.743960</td>\n",
       "      <td>1.633403</td>\n",
       "      <td>2.267614</td>\n",
       "      <td>1.870622</td>\n",
       "      <td>1.894889</td>\n",
       "      <td>2.135657</td>\n",
       "      <td>2.121268</td>\n",
       "      <td>2.111753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899998</th>\n",
       "      <td>1.845025</td>\n",
       "      <td>1.490592</td>\n",
       "      <td>1.072970</td>\n",
       "      <td>1.314346</td>\n",
       "      <td>1.063831</td>\n",
       "      <td>1.161041</td>\n",
       "      <td>2.081883</td>\n",
       "      <td>2.143744</td>\n",
       "      <td>2.155340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1899999</th>\n",
       "      <td>2.005812</td>\n",
       "      <td>1.691219</td>\n",
       "      <td>1.381235</td>\n",
       "      <td>2.031484</td>\n",
       "      <td>1.440333</td>\n",
       "      <td>1.927146</td>\n",
       "      <td>2.040518</td>\n",
       "      <td>2.094297</td>\n",
       "      <td>2.060633</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1900000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rotate_value  transe_value  distmult_value  originbert_value  \\\n",
       "0            1.257660      1.232071        1.214594          0.804364   \n",
       "1            1.513106      1.260692        1.624731          2.192274   \n",
       "2            1.390932      1.252307        1.328832          0.626029   \n",
       "3            1.364900      1.308151        0.314748         -0.257891   \n",
       "4            1.513106      1.260692        1.624731          2.192274   \n",
       "...               ...           ...             ...               ...   \n",
       "1899995      1.845025      1.490592        1.072970          1.314346   \n",
       "1899996      1.845025      1.720561        1.412775          1.961519   \n",
       "1899997      2.172254      1.743960        1.633403          2.267614   \n",
       "1899998      1.845025      1.490592        1.072970          1.314346   \n",
       "1899999      2.005812      1.691219        1.381235          2.031484   \n",
       "\n",
       "         pubmedbert_value  biobert_value  glm2_value  glm4_value  \\\n",
       "0                0.911068       0.734272    1.248592    1.252768   \n",
       "1                1.666998       1.705254    1.499834    1.493802   \n",
       "2                0.549827       0.445043    1.502856    1.431038   \n",
       "3                0.335758      -0.043891    1.491835    1.507580   \n",
       "4                1.666998       1.705254    1.499834    1.493802   \n",
       "...                   ...            ...         ...         ...   \n",
       "1899995          1.063831       1.161041    2.081883    2.143744   \n",
       "1899996          1.555589       1.677154    2.090156    2.152734   \n",
       "1899997          1.870622       1.894889    2.135657    2.121268   \n",
       "1899998          1.063831       1.161041    2.081883    2.143744   \n",
       "1899999          1.440333       1.927146    2.040518    2.094297   \n",
       "\n",
       "         llama3_value  label  \n",
       "0            1.252659      1  \n",
       "1            1.421188      0  \n",
       "2            1.507457      0  \n",
       "3            1.506920      0  \n",
       "4            1.421188      0  \n",
       "...               ...    ...  \n",
       "1899995      2.155340      0  \n",
       "1899996      2.025906      0  \n",
       "1899997      2.111753      0  \n",
       "1899998      2.155340      0  \n",
       "1899999      2.060633      0  \n",
       "\n",
       "[1900000 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store the final results\n",
    "final_result_list_test = []\n",
    "\n",
    "# Iterate over each row in index_df (3134 rows)\n",
    "for i in range(index_df.shape[0]):\n",
    "    # Iterate over each column in the current row\n",
    "    for col in range(index_df.shape[1]):\n",
    "        # Get the index value from the current cell\n",
    "        idx = index_df.iloc[i, col]\n",
    "\n",
    "        # Extract corresponding values from the standardized dataframes using the index and column\n",
    "        value_df1 = df1_standardized.iloc[idx, i]\n",
    "        value_df2 = df2_standardized.iloc[idx, i]\n",
    "        value_df3 = df3_standardized.iloc[idx, i]\n",
    "        value_df4 = df4_standardized.iloc[idx, i]\n",
    "        value_df5 = df5_standardized.iloc[idx, i]\n",
    "        value_df6 = df6_standardized.iloc[idx, i]\n",
    "        value_df7 = df7_standardized.iloc[idx, i]\n",
    "        value_df8 = df8_standardized.iloc[idx, i]\n",
    "        value_df9 = df9_standardized.iloc[idx, i]\n",
    "\n",
    "        # Assign label: 1 if this is the first column in the row, otherwise 0\n",
    "        label = 1 if col == 0 else 0\n",
    "\n",
    "        # Append the extracted values and label as a new record\n",
    "        final_result_list_test.append([\n",
    "            value_df1, value_df2, value_df3, value_df4, value_df5,\n",
    "            value_df6, value_df7, value_df8, value_df9, label\n",
    "        ])\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "final_result_df_test = pd.DataFrame(\n",
    "    final_result_list_test,\n",
    "    columns=[\n",
    "        'rotate_value', 'transe_value', 'distmult_value', 'originbert_value',\n",
    "        'pubmedbert_value', 'biobert_value', 'glm2_value', 'glm4_value',\n",
    "        'llama3_value', 'label'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Output the final DataFrame\n",
    "final_result_df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b35741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f0c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotate_value</th>\n",
       "      <th>transe_value</th>\n",
       "      <th>distmult_value</th>\n",
       "      <th>originbert_value</th>\n",
       "      <th>pubmedbert_value</th>\n",
       "      <th>biobert_value</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.730212</td>\n",
       "      <td>5.408730</td>\n",
       "      <td>7.030695</td>\n",
       "      <td>5.763075</td>\n",
       "      <td>5.296010</td>\n",
       "      <td>4.953124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.278990</td>\n",
       "      <td>6.350617</td>\n",
       "      <td>13.492573</td>\n",
       "      <td>8.052519</td>\n",
       "      <td>8.012822</td>\n",
       "      <td>6.226364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.121433</td>\n",
       "      <td>4.674488</td>\n",
       "      <td>5.154883</td>\n",
       "      <td>4.542877</td>\n",
       "      <td>2.779385</td>\n",
       "      <td>1.936759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.237035</td>\n",
       "      <td>6.398524</td>\n",
       "      <td>13.099855</td>\n",
       "      <td>6.027242</td>\n",
       "      <td>6.282642</td>\n",
       "      <td>6.590147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.896442</td>\n",
       "      <td>4.251971</td>\n",
       "      <td>1.400567</td>\n",
       "      <td>3.435893</td>\n",
       "      <td>2.750787</td>\n",
       "      <td>2.406645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41143</th>\n",
       "      <td>3.542073</td>\n",
       "      <td>3.974866</td>\n",
       "      <td>1.944354</td>\n",
       "      <td>2.857894</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>2.219810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41144</th>\n",
       "      <td>9.629985</td>\n",
       "      <td>5.844965</td>\n",
       "      <td>11.077765</td>\n",
       "      <td>7.719546</td>\n",
       "      <td>16.756503</td>\n",
       "      <td>6.529009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41145</th>\n",
       "      <td>0.553576</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>-0.221927</td>\n",
       "      <td>-0.600393</td>\n",
       "      <td>2.783667</td>\n",
       "      <td>1.096246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41146</th>\n",
       "      <td>10.360923</td>\n",
       "      <td>6.205590</td>\n",
       "      <td>11.483788</td>\n",
       "      <td>5.333828</td>\n",
       "      <td>4.833574</td>\n",
       "      <td>8.075562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41147</th>\n",
       "      <td>4.031383</td>\n",
       "      <td>3.772252</td>\n",
       "      <td>2.246169</td>\n",
       "      <td>1.965756</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>3.383029</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28158 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       rotate_value  transe_value  distmult_value  originbert_value  \\\n",
       "0          7.730212      5.408730        7.030695          5.763075   \n",
       "1         11.278990      6.350617       13.492573          8.052519   \n",
       "2          5.121433      4.674488        5.154883          4.542877   \n",
       "3         11.237035      6.398524       13.099855          6.027242   \n",
       "4          4.896442      4.251971        1.400567          3.435893   \n",
       "...             ...           ...             ...               ...   \n",
       "41143      3.542073      3.974866        1.944354          2.857894   \n",
       "41144      9.629985      5.844965       11.077765          7.719546   \n",
       "41145      0.553576      0.002269       -0.221927         -0.600393   \n",
       "41146     10.360923      6.205590       11.483788          5.333828   \n",
       "41147      4.031383      3.772252        2.246169          1.965756   \n",
       "\n",
       "       pubmedbert_value  biobert_value  label  \n",
       "0              5.296010       4.953124      1  \n",
       "1              8.012822       6.226364      0  \n",
       "2              2.779385       1.936759      0  \n",
       "3              6.282642       6.590147      0  \n",
       "4              2.750787       2.406645      0  \n",
       "...                 ...            ...    ...  \n",
       "41143          0.942934       2.219810      0  \n",
       "41144         16.756503       6.529009      0  \n",
       "41145          2.783667       1.096246      0  \n",
       "41146          4.833574       8.075562      0  \n",
       "41147          0.001650       3.383029      0  \n",
       "\n",
       "[28158 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ablation study\n",
    "\n",
    "# Drop columns 7, 8, and 9 (0-based indices 6, 7, 8)\n",
    "final_result_df_12 = final_result_df.drop(final_result_df.columns[[6, 7, 8]], axis=1)\n",
    "\n",
    "# Keep only the first 13 rows in every block of 19 rows\n",
    "keep_indices = [i for i in range(len(final_result_df_12)) if i % 19 < 13]\n",
    "\n",
    "# Alternative filtering options (commented out):\n",
    "# keep_indices = [i for i in range(len(final_result_df_13)) if not (7 <= i % 19 <= 12)]\n",
    "# keep_indices = [i for i in range(len(final_result_df_23)) if not (1 <= i % 19 <= 6)]\n",
    "\n",
    "# Apply the filtering to the DataFrame\n",
    "final_result_df_12 = final_result_df_12.iloc[keep_indices]\n",
    "\n",
    "final_result_df_12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba553689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM classifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC  # Import Support Vector Machine\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assume final_result_df is your DataFrame with shape (21938 rows × 4 columns)\n",
    "# Columns include 'rotate_value', 'transe_value', ..., 'llama3_value', and 'label'\n",
    "\n",
    "# 1. Define features and labels\n",
    "X = final_result_df[[\n",
    "    'rotate_value', 'transe_value', 'distmult_value', 'originbert_value',\n",
    "    'pubmedbert_value', 'biobert_value', 'glm2_value', 'glm4_value', 'llama3_value'\n",
    "]]  # Features\n",
    "y = final_result_df['label']  # Labels\n",
    "\n",
    "X_test = final_result_df_test[[\n",
    "    'rotate_value', 'transe_value', 'distmult_value', 'originbert_value',\n",
    "    'pubmedbert_value', 'biobert_value', 'glm2_value', 'glm4_value', 'llama3_value'\n",
    "]]  # Test features\n",
    "y_test = final_result_df_test['label']  # Test labels\n",
    "\n",
    "# 2. (Optional) Split dataset into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 3. Initialize the SVM model (you can specify parameters like kernel='linear' if needed)\n",
    "model = SVC(probability=True)\n",
    "# model = SVC(kernel='linear')\n",
    "\n",
    "# 4. Train the model on the entire dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# 5. Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6. Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 7. Print classification report with precision, recall, f1-score, etc.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: get model coefficients and intercept (only available for linear kernels)\n",
    "# w = model.coef_[0]\n",
    "# b = model.intercept_[0]\n",
    "# print(f\"Weights: {w}\")\n",
    "# print(f\"Intercept: {b}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Import Random Forest\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assume final_result_df is your DataFrame with shape (21938 rows × 4 columns)\n",
    "# Columns include 'rotate_value', 'transe_value', ..., 'llama3_value', and 'label'\n",
    "\n",
    "# 1. Define features and labels\n",
    "X = final_result_df[[\n",
    "    'rotate_value', 'transe_value', 'distmult_value', 'originbert_value',\n",
    "    'pubmedbert_value', 'biobert_value', 'glm2_value', 'glm4_value', 'llama3_value'\n",
    "]]  # Features\n",
    "y = final_result_df['label']  # Labels\n",
    "\n",
    "X_test = final_result_df_test[[\n",
    "    'rotate_value', 'transe_value', 'distmult_value', 'originbert_value',\n",
    "    'pubmedbert_value', 'biobert_value', 'glm2_value', 'glm4_value', 'llama3_value'\n",
    "]]  # Test features\n",
    "y_test = final_result_df_test['label']  # Test labels\n",
    "\n",
    "# 2. (Optional) Split dataset into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Initialize the Random Forest model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust n_estimators and other params\n",
    "\n",
    "# 4. Train the model on the entire dataset\n",
    "model.fit(X, y)\n",
    "\n",
    "# 5. Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 6. Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 7. Print classification report with precision, recall, f1-score, etc.\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. Output feature importances\n",
    "feature_importances = model.feature_importances_\n",
    "print(f\"Feature importances: {feature_importances}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e562fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume data loading\n",
    "X_train = final_result_df[['rotate_value', 'transe_value', 'distmult_value',\n",
    "                          'originbert_value', 'pubmedbert_value', 'biobert_value',\n",
    "                          'glm2_value', 'glm4_value', 'llama3_value']]  # Features\n",
    "y_train = final_result_df['label']  # Labels\n",
    "X_test = final_result_df_test[['rotate_value', 'transe_value', 'distmult_value',\n",
    "                              'originbert_value', 'pubmedbert_value', 'biobert_value',\n",
    "                              'glm2_value', 'glm4_value', 'llama3_value']]  # Features\n",
    "y_test = final_result_df_test['label']\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Define the neural network model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)   # Input layer to first hidden layer\n",
    "        self.fc2 = nn.Linear(128, 32)           # First hidden layer to second hidden layer\n",
    "        self.fc3 = nn.Linear(32, 1)             # Second hidden layer to output layer\n",
    "        self.sigmoid = nn.Sigmoid()             # Sigmoid activation for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))             # ReLU activation\n",
    "        x = torch.relu(self.fc2(x))             # ReLU activation\n",
    "        x = self.sigmoid(self.fc3(x))           # Sigmoid activation\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNN(X_train.shape[1])\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()                      # Binary Cross Entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()                             # Set model to training mode\n",
    "    optimizer.zero_grad()                     # Clear gradients from previous step\n",
    "\n",
    "    outputs = model(X_train_tensor).squeeze()  # Forward pass\n",
    "    loss = criterion(outputs, y_train_tensor.float())  # Calculate loss\n",
    "\n",
    "    loss.backward()                           # Backpropagation\n",
    "    optimizer.step()                          # Update model parameters\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()                                  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_pred_prob = model(X_test_tensor).squeeze().numpy()    # Predict probabilities\n",
    "    y_pred_label = (y_pred_prob > 0.5).astype(int)          # Threshold at 0.5 to get labels\n",
    "\n",
    "# Print prediction examples\n",
    "print(\"\\nPredicted Probabilities for the test set (first 5):\")\n",
    "print(y_pred_prob[:5])\n",
    "\n",
    "print(\"\\nPredicted Labels for the test set (first 5):\")\n",
    "print(y_pred_label[:5])\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_label)\n",
    "print(f\"\\nTest Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Optional: save the model\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Optional: load the model\n",
    "# model.load_state_dict(torch.load('model.pth'))\n",
    "# model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f63de89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume the CSV data for nine methods has already been loaded\n",
    "# (You can replace the file paths with actual paths as needed)\n",
    "df1 = pd.read_csv('rotate_test_rawscore.csv', index_col=0)\n",
    "df2 = pd.read_csv('transe_test_rawscore.csv', index_col=0)\n",
    "df3 = pd.read_csv('distmult_test_rawscore.csv', index_col=0)\n",
    "df4 = pd.read_csv('originbert_test_rawscore.csv', index_col=0)\n",
    "df5 = pd.read_csv('pubmedbert_test_rawscore.csv', index_col=0)\n",
    "df6 = pd.read_csv('biobert_test_rawscore.csv', index_col=0)\n",
    "df7 = pd.read_csv('GLM2_test_rawscore.csv', index_col=0)\n",
    "df8 = pd.read_csv('GLM4_test_rawscore.csv', index_col=0)\n",
    "df9 = pd.read_csv('llama3_test_rawscore.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7015776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Perform z-score standardization on the dataframes\n",
    "def standardize(df):\n",
    "    return (df - df.mean()) / df.std()\n",
    "\n",
    "# Apply standardization; note some are negated based on their logic\n",
    "df1_standardized = -standardize(df1)\n",
    "df2_standardized = -standardize(df2)\n",
    "df3_standardized = -standardize(df3)\n",
    "df4_standardized = standardize(df4)\n",
    "df5_standardized = standardize(df5)\n",
    "df6_standardized = standardize(df6)\n",
    "df7_standardized = -standardize(df7)\n",
    "df8_standardized = -standardize(df8)\n",
    "df9_standardized = -standardize(df9)\n",
    "\n",
    "# Optionally save standardized data\n",
    "# df1_standardized.to_csv('df1_standardized.csv', index=False)\n",
    "# df2_standardized.to_csv('df2_standardized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5d137d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 576,\n",
       " 1: 346,\n",
       " 2: 520,\n",
       " 3: 224,\n",
       " 4: 618,\n",
       " 5: 285,\n",
       " 6: 509,\n",
       " 7: 634,\n",
       " 8: 614,\n",
       " 9: 564,\n",
       " 10: 444,\n",
       " 11: 320,\n",
       " 12: 476,\n",
       " 13: 529,\n",
       " 14: 569,\n",
       " 15: 639,\n",
       " 16: 453,\n",
       " 17: 634,\n",
       " 18: 21,\n",
       " 19: 516,\n",
       " 20: 240,\n",
       " 21: 530,\n",
       " 22: 603,\n",
       " 23: 347,\n",
       " 24: 405,\n",
       " 25: 623,\n",
       " 26: 176,\n",
       " 27: 605,\n",
       " 28: 563,\n",
       " 29: 228,\n",
       " 30: 118,\n",
       " 31: 621,\n",
       " 32: 315,\n",
       " 33: 619,\n",
       " 34: 626,\n",
       " 35: 503,\n",
       " 36: 530,\n",
       " 37: 33,\n",
       " 38: 458,\n",
       " 39: 420,\n",
       " 40: 509,\n",
       " 41: 245,\n",
       " 42: 150,\n",
       " 43: 392,\n",
       " 44: 485,\n",
       " 45: 292,\n",
       " 46: 106,\n",
       " 47: 509,\n",
       " 48: 148,\n",
       " 49: 15,\n",
       " 50: 485,\n",
       " 51: 543,\n",
       " 52: 436,\n",
       " 53: 569,\n",
       " 54: 369,\n",
       " 55: 184,\n",
       " 56: 538,\n",
       " 57: 344,\n",
       " 58: 320,\n",
       " 59: 327,\n",
       " 60: 605,\n",
       " 61: 137,\n",
       " 62: 22,\n",
       " 63: 434,\n",
       " 64: 47,\n",
       " 65: 292,\n",
       " 66: 623,\n",
       " 67: 190,\n",
       " 68: 39,\n",
       " 69: 642,\n",
       " 70: 260,\n",
       " 71: 642,\n",
       " 72: 348,\n",
       " 73: 152,\n",
       " 74: 413,\n",
       " 75: 494,\n",
       " 76: 590,\n",
       " 77: 157,\n",
       " 78: 521,\n",
       " 79: 220,\n",
       " 80: 436,\n",
       " 81: 226,\n",
       " 82: 258,\n",
       " 83: 271,\n",
       " 84: 98,\n",
       " 85: 405,\n",
       " 86: 397,\n",
       " 87: 278,\n",
       " 88: 315,\n",
       " 89: 634,\n",
       " 90: 245,\n",
       " 91: 285,\n",
       " 92: 141,\n",
       " 93: 436,\n",
       " 94: 176,\n",
       " 95: 84,\n",
       " 96: 2,\n",
       " 97: 228,\n",
       " 98: 506,\n",
       " 99: 349,\n",
       " 100: 149,\n",
       " 101: 551,\n",
       " 102: 547,\n",
       " 103: 9,\n",
       " 104: 148,\n",
       " 105: 425,\n",
       " 106: 492,\n",
       " 107: 194,\n",
       " 108: 620,\n",
       " 109: 358,\n",
       " 110: 571,\n",
       " 111: 279,\n",
       " 112: 375,\n",
       " 113: 142,\n",
       " 114: 418,\n",
       " 115: 139,\n",
       " 116: 619,\n",
       " 117: 199,\n",
       " 118: 438,\n",
       " 119: 552,\n",
       " 120: 599,\n",
       " 121: 529,\n",
       " 122: 251,\n",
       " 123: 186,\n",
       " 124: 341,\n",
       " 125: 622,\n",
       " 126: 524,\n",
       " 127: 267,\n",
       " 128: 456,\n",
       " 129: 182,\n",
       " 130: 569,\n",
       " 131: 475,\n",
       " 132: 22,\n",
       " 133: 99,\n",
       " 134: 371,\n",
       " 135: 378,\n",
       " 136: 327,\n",
       " 137: 618,\n",
       " 138: 560,\n",
       " 139: 394,\n",
       " 140: 57,\n",
       " 141: 621,\n",
       " 142: 521,\n",
       " 143: 624,\n",
       " 144: 623,\n",
       " 145: 420,\n",
       " 146: 634,\n",
       " 147: 376,\n",
       " 148: 503,\n",
       " 149: 569,\n",
       " 150: 456,\n",
       " 151: 248,\n",
       " 152: 348,\n",
       " 153: 230,\n",
       " 154: 591,\n",
       " 155: 596,\n",
       " 156: 396,\n",
       " 157: 22,\n",
       " 158: 355,\n",
       " 159: 511,\n",
       " 160: 182,\n",
       " 161: 515,\n",
       " 162: 494,\n",
       " 163: 266,\n",
       " 164: 106,\n",
       " 165: 193,\n",
       " 166: 148,\n",
       " 167: 375,\n",
       " 168: 285,\n",
       " 169: 324,\n",
       " 170: 636,\n",
       " 171: 442,\n",
       " 172: 605,\n",
       " 173: 623,\n",
       " 174: 75,\n",
       " 175: 621,\n",
       " 176: 147,\n",
       " 177: 458,\n",
       " 178: 315,\n",
       " 179: 67,\n",
       " 180: 219,\n",
       " 181: 54,\n",
       " 182: 530,\n",
       " 183: 212,\n",
       " 184: 291,\n",
       " 185: 174,\n",
       " 186: 118,\n",
       " 187: 210,\n",
       " 188: 390,\n",
       " 189: 543,\n",
       " 190: 448,\n",
       " 191: 327,\n",
       " 192: 152,\n",
       " 193: 433,\n",
       " 194: 599,\n",
       " 195: 150,\n",
       " 196: 351,\n",
       " 197: 618,\n",
       " 198: 506,\n",
       " 199: 176,\n",
       " 200: 436,\n",
       " 201: 315,\n",
       " 202: 198,\n",
       " 203: 245,\n",
       " 204: 437,\n",
       " 205: 448,\n",
       " 206: 484,\n",
       " 207: 606,\n",
       " 208: 504,\n",
       " 209: 640,\n",
       " 210: 492,\n",
       " 211: 444,\n",
       " 212: 77,\n",
       " 213: 285,\n",
       " 214: 292,\n",
       " 215: 453,\n",
       " 216: 547,\n",
       " 217: 396,\n",
       " 218: 591,\n",
       " 219: 104,\n",
       " 220: 621,\n",
       " 221: 196,\n",
       " 222: 226,\n",
       " 223: 621,\n",
       " 224: 563,\n",
       " 225: 157,\n",
       " 226: 224,\n",
       " 227: 324,\n",
       " 228: 540,\n",
       " 229: 595,\n",
       " 230: 434,\n",
       " 231: 395,\n",
       " 232: 22,\n",
       " 233: 634,\n",
       " 234: 618,\n",
       " 235: 585,\n",
       " 236: 595,\n",
       " 237: 179,\n",
       " 238: 431,\n",
       " 239: 303,\n",
       " 240: 640,\n",
       " 241: 153,\n",
       " 242: 248,\n",
       " 243: 485,\n",
       " 244: 569,\n",
       " 245: 638,\n",
       " 246: 320,\n",
       " 247: 226,\n",
       " 248: 258,\n",
       " 249: 642,\n",
       " 250: 245,\n",
       " 251: 315,\n",
       " 252: 534,\n",
       " 253: 404,\n",
       " 254: 543,\n",
       " 255: 567,\n",
       " 256: 484,\n",
       " 257: 75,\n",
       " 258: 529,\n",
       " 259: 490,\n",
       " 260: 258,\n",
       " 261: 526,\n",
       " 262: 478,\n",
       " 263: 618,\n",
       " 264: 503,\n",
       " 265: 298,\n",
       " 266: 371,\n",
       " 267: 396,\n",
       " 268: 344,\n",
       " 269: 343,\n",
       " 270: 224,\n",
       " 271: 224,\n",
       " 272: 185,\n",
       " 273: 599,\n",
       " 274: 348,\n",
       " 275: 520,\n",
       " 276: 481,\n",
       " 277: 484,\n",
       " 278: 526,\n",
       " 279: 614,\n",
       " 280: 396,\n",
       " 281: 551,\n",
       " 282: 526,\n",
       " 283: 548,\n",
       " 284: 526,\n",
       " 285: 265,\n",
       " 286: 225,\n",
       " 287: 508,\n",
       " 288: 566,\n",
       " 289: 291,\n",
       " 290: 294,\n",
       " 291: 173,\n",
       " 292: 272,\n",
       " 293: 117,\n",
       " 294: 375,\n",
       " 295: 331,\n",
       " 296: 560,\n",
       " 297: 475,\n",
       " 298: 548,\n",
       " 299: 615,\n",
       " 300: 564,\n",
       " 301: 121,\n",
       " 302: 592,\n",
       " 303: 634,\n",
       " 304: 49,\n",
       " 305: 94,\n",
       " 306: 509,\n",
       " 307: 508,\n",
       " 308: 293,\n",
       " 309: 376,\n",
       " 310: 642,\n",
       " 311: 198,\n",
       " 312: 384,\n",
       " 313: 560,\n",
       " 314: 227,\n",
       " 315: 348,\n",
       " 316: 603,\n",
       " 317: 293,\n",
       " 318: 444,\n",
       " 319: 605,\n",
       " 320: 431,\n",
       " 321: 320,\n",
       " 322: 348,\n",
       " 323: 253,\n",
       " 324: 117,\n",
       " 325: 506,\n",
       " 326: 441,\n",
       " 327: 540,\n",
       " 328: 272,\n",
       " 329: 617,\n",
       " 330: 526,\n",
       " 331: 396,\n",
       " 332: 275,\n",
       " 333: 294,\n",
       " 334: 508,\n",
       " 335: 320,\n",
       " 336: 456,\n",
       " 337: 615,\n",
       " 338: 548,\n",
       " 339: 224,\n",
       " 340: 84,\n",
       " 341: 309,\n",
       " 342: 440,\n",
       " 343: 539,\n",
       " 344: 509,\n",
       " 345: 94,\n",
       " 346: 141,\n",
       " 347: 435,\n",
       " 348: 376,\n",
       " 349: 533,\n",
       " 350: 435,\n",
       " 351: 90,\n",
       " 352: 416,\n",
       " 353: 395,\n",
       " 354: 526,\n",
       " 355: 331,\n",
       " 356: 244,\n",
       " 357: 521,\n",
       " 358: 446,\n",
       " 359: 171,\n",
       " 360: 568,\n",
       " 361: 552,\n",
       " 362: 563,\n",
       " 363: 544,\n",
       " 364: 395,\n",
       " 365: 346,\n",
       " 366: 508,\n",
       " 367: 530,\n",
       " 368: 397,\n",
       " 369: 393,\n",
       " 370: 143,\n",
       " 371: 137,\n",
       " 372: 53,\n",
       " 373: 618,\n",
       " 374: 542,\n",
       " 375: 155,\n",
       " 376: 355,\n",
       " 377: 614,\n",
       " 378: 551,\n",
       " 379: 609,\n",
       " 380: 504,\n",
       " 381: 182,\n",
       " 382: 378,\n",
       " 383: 560,\n",
       " 384: 366,\n",
       " 385: 172,\n",
       " 386: 404,\n",
       " 387: 439,\n",
       " 388: 155,\n",
       " 389: 503,\n",
       " 390: 172,\n",
       " 391: 172,\n",
       " 392: 436,\n",
       " 393: 491,\n",
       " 394: 277,\n",
       " 395: 486,\n",
       " 396: 378,\n",
       " 397: 78,\n",
       " 398: 530,\n",
       " 399: 478,\n",
       " 400: 533,\n",
       " 401: 395,\n",
       " 402: 397,\n",
       " 403: 228,\n",
       " 404: 436,\n",
       " 405: 603,\n",
       " 406: 252,\n",
       " 407: 436,\n",
       " 408: 615,\n",
       " 409: 484,\n",
       " 410: 572,\n",
       " 411: 635,\n",
       " 412: 335,\n",
       " 413: 359,\n",
       " 414: 481,\n",
       " 415: 404,\n",
       " 416: 358,\n",
       " 417: 526,\n",
       " 418: 320,\n",
       " 419: 436,\n",
       " 420: 567,\n",
       " 421: 355,\n",
       " 422: 526,\n",
       " 423: 149,\n",
       " 424: 317,\n",
       " 425: 529,\n",
       " 426: 458,\n",
       " 427: 370,\n",
       " 428: 396,\n",
       " 429: 102,\n",
       " 430: 22,\n",
       " 431: 245,\n",
       " 432: 612,\n",
       " 433: 364,\n",
       " 434: 376,\n",
       " 435: 491,\n",
       " 436: 75,\n",
       " 437: 434,\n",
       " 438: 152,\n",
       " 439: 516,\n",
       " 440: 595,\n",
       " 441: 623,\n",
       " 442: 272,\n",
       " 443: 184,\n",
       " 444: 532,\n",
       " 445: 384,\n",
       " 446: 9,\n",
       " 447: 571,\n",
       " 448: 227,\n",
       " 449: 618,\n",
       " 450: 291,\n",
       " 451: 569,\n",
       " 452: 623,\n",
       " 453: 106,\n",
       " 454: 485,\n",
       " 455: 526,\n",
       " 456: 157,\n",
       " 457: 393,\n",
       " 458: 435,\n",
       " 459: 369,\n",
       " 460: 516,\n",
       " 461: 395,\n",
       " 462: 526,\n",
       " 463: 193,\n",
       " 464: 390,\n",
       " 465: 560,\n",
       " 466: 509,\n",
       " 467: 293,\n",
       " 468: 542,\n",
       " 469: 490,\n",
       " 470: 552,\n",
       " 471: 375,\n",
       " 472: 589,\n",
       " 473: 642,\n",
       " 474: 198,\n",
       " 475: 149,\n",
       " 476: 484,\n",
       " 477: 405,\n",
       " 478: 574,\n",
       " 479: 552,\n",
       " 480: 294,\n",
       " 481: 75,\n",
       " 482: 293,\n",
       " 483: 303,\n",
       " 484: 513,\n",
       " 485: 22,\n",
       " 486: 484,\n",
       " 487: 274,\n",
       " 488: 447,\n",
       " 489: 621,\n",
       " 490: 377,\n",
       " 491: 426,\n",
       " 492: 458,\n",
       " 493: 52,\n",
       " 494: 510,\n",
       " 495: 412,\n",
       " 496: 590,\n",
       " 497: 613,\n",
       " 498: 543,\n",
       " 499: 491,\n",
       " 500: 416,\n",
       " 501: 391,\n",
       " 502: 575,\n",
       " 503: 568,\n",
       " 504: 141,\n",
       " 505: 396,\n",
       " 506: 435,\n",
       " 507: 177,\n",
       " 508: 212,\n",
       " 509: 564,\n",
       " 510: 349,\n",
       " 511: 605,\n",
       " 512: 218,\n",
       " 513: 266,\n",
       " 514: 121,\n",
       " 515: 98,\n",
       " 516: 176,\n",
       " 517: 599,\n",
       " 518: 599,\n",
       " 519: 437,\n",
       " 520: 599,\n",
       " 521: 47,\n",
       " 522: 545,\n",
       " 523: 47,\n",
       " 524: 118,\n",
       " 525: 485,\n",
       " 526: 598,\n",
       " 527: 449,\n",
       " 528: 341,\n",
       " 529: 530,\n",
       " 530: 101,\n",
       " 531: 605,\n",
       " 532: 434,\n",
       " 533: 287,\n",
       " 534: 531,\n",
       " 535: 558,\n",
       " 536: 434,\n",
       " 537: 494,\n",
       " 538: 315,\n",
       " 539: 458,\n",
       " 540: 309,\n",
       " 541: 326,\n",
       " 542: 434,\n",
       " 543: 326,\n",
       " 544: 229,\n",
       " 545: 436,\n",
       " 546: 506,\n",
       " 547: 438,\n",
       " 548: 568,\n",
       " 549: 543,\n",
       " 550: 620,\n",
       " 551: 567,\n",
       " 552: 596,\n",
       " 553: 619,\n",
       " 554: 344,\n",
       " 555: 482,\n",
       " 556: 193,\n",
       " 557: 539,\n",
       " 558: 315,\n",
       " 559: 599,\n",
       " 560: 346,\n",
       " 561: 558,\n",
       " 562: 279,\n",
       " 563: 412,\n",
       " 564: 640,\n",
       " 565: 426,\n",
       " 566: 495,\n",
       " 567: 572,\n",
       " 568: 507,\n",
       " 569: 379,\n",
       " 570: 362,\n",
       " 571: 233,\n",
       " 572: 456,\n",
       " 573: 378,\n",
       " 574: 530,\n",
       " 575: 49,\n",
       " 576: 121,\n",
       " 577: 47,\n",
       " 578: 378,\n",
       " 579: 143,\n",
       " 580: 331,\n",
       " 581: 458,\n",
       " 582: 529,\n",
       " 583: 192,\n",
       " 584: 76,\n",
       " 585: 67,\n",
       " 586: 245,\n",
       " 587: 173,\n",
       " 588: 639,\n",
       " 589: 381,\n",
       " 590: 526,\n",
       " 591: 492,\n",
       " 592: 434,\n",
       " 593: 538,\n",
       " 594: 448,\n",
       " 595: 529,\n",
       " 596: 431,\n",
       " 597: 338,\n",
       " 598: 618,\n",
       " 599: 376,\n",
       " 600: 341,\n",
       " 601: 391,\n",
       " 602: 143,\n",
       " 603: 643,\n",
       " 604: 75,\n",
       " 605: 619,\n",
       " 606: 253,\n",
       " 607: 614,\n",
       " 608: 223,\n",
       " 609: 95,\n",
       " 610: 289,\n",
       " 611: 515,\n",
       " 612: 558,\n",
       " 613: 585,\n",
       " 614: 260,\n",
       " 615: 558,\n",
       " 616: 458,\n",
       " 617: 492,\n",
       " 618: 621,\n",
       " 619: 569,\n",
       " 620: 484,\n",
       " 621: 452,\n",
       " 622: 615,\n",
       " 623: 246,\n",
       " 624: 482,\n",
       " 625: 349,\n",
       " 626: 275,\n",
       " 627: 486,\n",
       " 628: 7,\n",
       " 629: 102,\n",
       " 630: 103,\n",
       " 631: 177,\n",
       " 632: 506,\n",
       " 633: 198,\n",
       " 634: 378,\n",
       " 635: 2,\n",
       " 636: 320,\n",
       " 637: 135,\n",
       " 638: 548,\n",
       " 639: 386,\n",
       " 640: 439,\n",
       " 641: 285,\n",
       " 642: 258,\n",
       " 643: 481,\n",
       " 644: 503,\n",
       " 645: 315,\n",
       " 646: 438,\n",
       " 647: 481,\n",
       " 648: 293,\n",
       " 649: 567,\n",
       " 650: 520,\n",
       " 651: 506,\n",
       " 652: 642,\n",
       " 653: 509,\n",
       " 654: 212,\n",
       " 655: 507,\n",
       " 656: 529,\n",
       " 657: 485,\n",
       " 658: 224,\n",
       " 659: 503,\n",
       " 660: 480,\n",
       " 661: 92,\n",
       " 662: 538,\n",
       " 663: 605,\n",
       " 664: 504,\n",
       " 665: 250,\n",
       " 666: 362,\n",
       " 667: 220,\n",
       " 668: 599,\n",
       " 669: 475,\n",
       " 670: 623,\n",
       " 671: 386,\n",
       " 672: 638,\n",
       " 673: 117,\n",
       " 674: 258,\n",
       " 675: 592,\n",
       " 676: 508,\n",
       " 677: 230,\n",
       " 678: 543,\n",
       " 679: 590,\n",
       " 680: 613,\n",
       " 681: 628,\n",
       " 682: 75,\n",
       " 683: 94,\n",
       " 684: 541,\n",
       " 685: 482,\n",
       " 686: 204,\n",
       " 687: 515,\n",
       " 688: 504,\n",
       " 689: 526,\n",
       " 690: 374,\n",
       " 691: 291,\n",
       " 692: 543,\n",
       " 693: 533,\n",
       " 694: 441,\n",
       " 695: 590,\n",
       " 696: 526,\n",
       " 697: 421,\n",
       " 698: 376,\n",
       " 699: 366,\n",
       " 700: 260,\n",
       " 701: 494,\n",
       " 702: 603,\n",
       " 703: 141,\n",
       " 704: 43,\n",
       " 705: 240,\n",
       " 706: 393,\n",
       " 707: 25,\n",
       " 708: 623,\n",
       " 709: 558,\n",
       " 710: 448,\n",
       " 711: 330,\n",
       " 712: 420,\n",
       " 713: 99,\n",
       " 714: 431,\n",
       " 715: 22,\n",
       " 716: 393,\n",
       " 717: 450,\n",
       " 718: 436,\n",
       " 719: 615,\n",
       " 720: 521,\n",
       " 721: 538,\n",
       " 722: 351,\n",
       " 723: 344,\n",
       " 724: 509,\n",
       " 725: 320,\n",
       " 726: 526,\n",
       " 727: 225,\n",
       " 728: 22,\n",
       " 729: 32,\n",
       " 730: 539,\n",
       " 731: 393,\n",
       " 732: 640,\n",
       " 733: 456,\n",
       " 734: 313,\n",
       " 735: 380,\n",
       " 736: 436,\n",
       " 737: 450,\n",
       " 738: 338,\n",
       " 739: 420,\n",
       " 740: 344,\n",
       " 741: 393,\n",
       " 742: 526,\n",
       " 743: 374,\n",
       " 744: 375,\n",
       " 745: 450,\n",
       " 746: 456,\n",
       " 747: 227,\n",
       " 748: 543,\n",
       " 749: 444,\n",
       " 750: 331,\n",
       " 751: 617,\n",
       " 752: 434,\n",
       " 753: 281,\n",
       " 754: 542,\n",
       " 755: 433,\n",
       " 756: 567,\n",
       " 757: 490,\n",
       " 758: 558,\n",
       " 759: 626,\n",
       " 760: 376,\n",
       " 761: 482,\n",
       " 762: 458,\n",
       " 763: 358,\n",
       " 764: 587,\n",
       " 765: 344,\n",
       " 766: 426,\n",
       " 767: 434,\n",
       " 768: 482,\n",
       " 769: 260,\n",
       " 770: 320,\n",
       " 771: 585,\n",
       " 772: 285,\n",
       " 773: 555,\n",
       " 774: 281,\n",
       " 775: 576,\n",
       " 776: 376,\n",
       " 777: 614,\n",
       " 778: 349,\n",
       " 779: 452,\n",
       " 780: 121,\n",
       " 781: 347,\n",
       " 782: 29,\n",
       " 783: 349,\n",
       " 784: 517,\n",
       " 785: 623,\n",
       " 786: 627,\n",
       " 787: 309,\n",
       " 788: 526,\n",
       " 789: 595,\n",
       " 790: 433,\n",
       " 791: 320,\n",
       " 792: 393,\n",
       " 793: 315,\n",
       " 794: 196,\n",
       " 795: 233,\n",
       " 796: 375,\n",
       " 797: 198,\n",
       " 798: 245,\n",
       " 799: 439,\n",
       " 800: 599,\n",
       " 801: 157,\n",
       " 802: 348,\n",
       " 803: 386,\n",
       " 804: 635,\n",
       " 805: 359,\n",
       " 806: 452,\n",
       " 807: 485,\n",
       " 808: 348,\n",
       " 809: 438,\n",
       " 810: 297,\n",
       " 811: 323,\n",
       " 812: 266,\n",
       " 813: 106,\n",
       " 814: 224,\n",
       " 815: 22,\n",
       " 816: 615,\n",
       " 817: 141,\n",
       " 818: 22,\n",
       " 819: 485,\n",
       " 820: 269,\n",
       " 821: 242,\n",
       " 822: 583,\n",
       " 823: 482,\n",
       " 824: 576,\n",
       " 825: 92,\n",
       " 826: 364,\n",
       " 827: 139,\n",
       " 828: 115,\n",
       " 829: 224,\n",
       " 830: 466,\n",
       " 831: 504,\n",
       " 832: 438,\n",
       " 833: 643,\n",
       " 834: 435,\n",
       " 835: 547,\n",
       " 836: 603,\n",
       " 837: 640,\n",
       " 838: 379,\n",
       " 839: 55,\n",
       " 840: 351,\n",
       " 841: 324,\n",
       " 842: 614,\n",
       " 843: 563,\n",
       " 844: 509,\n",
       " 845: 454,\n",
       " 846: 458,\n",
       " 847: 245,\n",
       " 848: 557,\n",
       " 849: 198,\n",
       " 850: 47,\n",
       " 851: 560,\n",
       " 852: 426,\n",
       " 853: 530,\n",
       " 854: 515,\n",
       " 855: 642,\n",
       " 856: 492,\n",
       " 857: 275,\n",
       " 858: 633,\n",
       " 859: 541,\n",
       " 860: 101,\n",
       " 861: 348,\n",
       " 862: 590,\n",
       " 863: 439,\n",
       " 864: 382,\n",
       " 865: 426,\n",
       " 866: 253,\n",
       " 867: 291,\n",
       " 868: 564,\n",
       " 869: 433,\n",
       " 870: 634,\n",
       " 871: 430,\n",
       " 872: 182,\n",
       " 873: 538,\n",
       " 874: 118,\n",
       " 875: 539,\n",
       " 876: 116,\n",
       " 877: 226,\n",
       " 878: 295,\n",
       " 879: 431,\n",
       " 880: 196,\n",
       " 881: 348,\n",
       " 882: 34,\n",
       " 883: 619,\n",
       " 884: 453,\n",
       " 885: 242,\n",
       " 886: 298,\n",
       " 887: 140,\n",
       " 888: 576,\n",
       " 889: 141,\n",
       " 890: 503,\n",
       " 891: 172,\n",
       " 892: 539,\n",
       " 893: 302,\n",
       " 894: 224,\n",
       " 895: 539,\n",
       " 896: 621,\n",
       " 897: 198,\n",
       " 898: 203,\n",
       " 899: 569,\n",
       " 900: 18,\n",
       " 901: 486,\n",
       " 902: 579,\n",
       " 903: 634,\n",
       " 904: 137,\n",
       " 905: 426,\n",
       " 906: 526,\n",
       " 907: 98,\n",
       " 908: 485,\n",
       " 909: 24,\n",
       " 910: 450,\n",
       " 911: 331,\n",
       " 912: 266,\n",
       " 913: 338,\n",
       " 914: 438,\n",
       " 915: 355,\n",
       " 916: 564,\n",
       " 917: 450,\n",
       " 918: 526,\n",
       " 919: 131,\n",
       " 920: 583,\n",
       " 921: 33,\n",
       " 922: 396,\n",
       " 923: 480,\n",
       " 924: 642,\n",
       " 925: 566,\n",
       " 926: 210,\n",
       " 927: 634,\n",
       " 928: 431,\n",
       " 929: 269,\n",
       " 930: 396,\n",
       " 931: 615,\n",
       " 932: 506,\n",
       " 933: 64,\n",
       " 934: 285,\n",
       " 935: 533,\n",
       " 936: 14,\n",
       " 937: 387,\n",
       " 938: 98,\n",
       " 939: 245,\n",
       " 940: 198,\n",
       " 941: 364,\n",
       " 942: 623,\n",
       " 943: 47,\n",
       " 944: 475,\n",
       " 945: 279,\n",
       " 946: 591,\n",
       " 947: 590,\n",
       " 948: 478,\n",
       " 949: 324,\n",
       " 950: 486,\n",
       " 951: 621,\n",
       " 952: 486,\n",
       " 953: 293,\n",
       " 954: 341,\n",
       " 955: 438,\n",
       " 956: 260,\n",
       " 957: 456,\n",
       " 958: 344,\n",
       " 959: 492,\n",
       " 960: 635,\n",
       " 961: 172,\n",
       " 962: 454,\n",
       " 963: 624,\n",
       " 964: 366,\n",
       " 965: 292,\n",
       " 966: 570,\n",
       " 967: 603,\n",
       " 968: 520,\n",
       " 969: 50,\n",
       " 970: 478,\n",
       " 971: 274,\n",
       " 972: 530,\n",
       " 973: 485,\n",
       " 974: 217,\n",
       " 975: 396,\n",
       " 976: 344,\n",
       " 977: 640,\n",
       " 978: 355,\n",
       " 979: 274,\n",
       " 980: 345,\n",
       " 981: 248,\n",
       " 982: 590,\n",
       " 983: 434,\n",
       " 984: 570,\n",
       " 985: 396,\n",
       " 986: 198,\n",
       " 987: 575,\n",
       " 988: 572,\n",
       " 989: 141,\n",
       " 990: 379,\n",
       " 991: 506,\n",
       " 992: 484,\n",
       " 993: 590,\n",
       " 994: 431,\n",
       " 995: 635,\n",
       " 996: 98,\n",
       " 997: 484,\n",
       " 998: 117,\n",
       " 999: 619,\n",
       " ...}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"transe_test_true_score.xlsx\")\n",
    "\n",
    "dictrue = {index: key for index, key in zip(df.index, df['Key'])}\n",
    "print(len(dictrue))\n",
    "dictrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732f824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability_0</th>\n",
       "      <th>probability_1</th>\n",
       "      <th>probability_2</th>\n",
       "      <th>probability_3</th>\n",
       "      <th>probability_4</th>\n",
       "      <th>probability_5</th>\n",
       "      <th>probability_6</th>\n",
       "      <th>probability_7</th>\n",
       "      <th>probability_8</th>\n",
       "      <th>probability_9</th>\n",
       "      <th>...</th>\n",
       "      <th>probability_2157</th>\n",
       "      <th>probability_2158</th>\n",
       "      <th>probability_2159</th>\n",
       "      <th>probability_2160</th>\n",
       "      <th>probability_2161</th>\n",
       "      <th>probability_2162</th>\n",
       "      <th>probability_2163</th>\n",
       "      <th>probability_2164</th>\n",
       "      <th>probability_2165</th>\n",
       "      <th>probability_2166</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.010637</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.01679</td>\n",
       "      <td>0.013415</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.041791</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.00226</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.007596</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.011746</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.001754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5648</th>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.00079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.00122</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5651</th>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.00121</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.001302</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5652</th>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.00054</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.00035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5653 rows × 2167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     probability_0 probability_1 probability_2 probability_3 probability_4  \\\n",
       "0         0.000691      0.010637      0.009819      0.003719       0.01679   \n",
       "1         0.002143      0.000536      0.000576      0.002143      0.001065   \n",
       "2         0.001302      0.001065      0.000472      0.000519      0.000327   \n",
       "3          0.00035      0.011746      0.000472      0.000356      0.001782   \n",
       "4          0.00035      0.001892      0.003095       0.00035      0.001505   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "5648      0.000596      0.001302      0.003218      0.001065      0.000328   \n",
       "5649      0.002009      0.000391       0.00035      0.000435      0.000592   \n",
       "5650      0.000328       0.00122      0.000286      0.000328      0.002003   \n",
       "5651      0.001065      0.003145      0.001754      0.001754      0.001065   \n",
       "5652      0.000325      0.000934      0.002009      0.002143      0.000913   \n",
       "\n",
       "     probability_5 probability_6 probability_7 probability_8 probability_9  \\\n",
       "0         0.013415      0.004949      0.007378      0.006634      0.003634   \n",
       "1          0.00054      0.001302      0.000479      0.001302      0.001754   \n",
       "2         0.003922      0.002428      0.001065      0.000536       0.00121   \n",
       "3          0.00054       0.00054      0.001754      0.001065      0.001065   \n",
       "4         0.000723      0.000328      0.000286      0.000472      0.002428   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "5648      0.001302      0.001754      0.002003       0.00035      0.001754   \n",
       "5649      0.000286      0.001065       0.00121      0.002143      0.000327   \n",
       "5650       0.00121      0.002009      0.001754      0.002143      0.019469   \n",
       "5651      0.000286       0.00121      0.000418      0.001302      0.001065   \n",
       "5652      0.000646       0.00054      0.000576      0.002009      0.000445   \n",
       "\n",
       "      ... probability_2157 probability_2158 probability_2159 probability_2160  \\\n",
       "0     ...         0.003184         0.009712         0.002185         0.041791   \n",
       "1     ...         0.000328         0.001065         0.002143         0.000392   \n",
       "2     ...         0.001302         0.000453         0.001302          0.00035   \n",
       "3     ...          0.00035         0.000451         0.000472         0.000479   \n",
       "4     ...         0.000723          0.00054         0.002143         0.000408   \n",
       "...   ...              ...              ...              ...              ...   \n",
       "5648  ...         0.003384         0.000472         0.002009         0.000286   \n",
       "5649  ...         0.000328         0.000669         0.002009         0.000328   \n",
       "5650  ...         0.001065          0.00035         0.001754          0.00122   \n",
       "5651  ...         0.000529         0.005783         0.001065         0.001065   \n",
       "5652  ...         0.000536         0.002009         0.000356         0.000449   \n",
       "\n",
       "     probability_2161 probability_2162 probability_2163 probability_2164  \\\n",
       "0            0.000526          0.00081         0.000644         0.001174   \n",
       "1            0.001302         0.001618         0.007596         0.001302   \n",
       "2            0.000325         0.001065          0.00121          0.00035   \n",
       "3            0.001302         0.001065         0.001259         0.000286   \n",
       "4             0.00121         0.001754          0.00122         0.000576   \n",
       "...               ...              ...              ...              ...   \n",
       "5648         0.000472         0.000328          0.00035          0.00122   \n",
       "5649         0.001325         0.001993         0.000328         0.000328   \n",
       "5650         0.000576         0.001754         0.001065         0.002143   \n",
       "5651         0.001065         0.000328         0.001065         0.000576   \n",
       "5652         0.003731         0.001159         0.001136         0.000472   \n",
       "\n",
       "     probability_2165 probability_2166  \n",
       "0             0.00226         0.002633  \n",
       "1            0.001302         0.000488  \n",
       "2            0.000506         0.000536  \n",
       "3             0.00122         0.001754  \n",
       "4            0.002143         0.000646  \n",
       "...               ...              ...  \n",
       "5648          0.00122         0.000596  \n",
       "5649         0.001618          0.00079  \n",
       "5650         0.000536         0.002143  \n",
       "5651         0.000286         0.000286  \n",
       "5652         0.000435          0.00035  \n",
       "\n",
       "[5653 rows x 2167 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM prediction\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize an empty DataFrame to store prediction probabilities\n",
    "probability_results = pd.DataFrame(\n",
    "    index=df1_standardized.index,\n",
    "    columns=[f'probability_{i}' for i in range(df1_standardized.shape[1])]\n",
    ")\n",
    "\n",
    "# Iterate over each column to make predictions\n",
    "for i in range(df1_standardized.shape[1]):\n",
    "    # Extract the i-th column from each standardized dataframe as features\n",
    "    X1 = df1_standardized.iloc[:, i]\n",
    "    X2 = df2_standardized.iloc[:, i]\n",
    "    X3 = df3_standardized.iloc[:, i]\n",
    "    X4 = df4_standardized.iloc[:, i]\n",
    "    X5 = df5_standardized.iloc[:, i]\n",
    "    X6 = df6_standardized.iloc[:, i]\n",
    "    X7 = df7_standardized.iloc[:, i]\n",
    "    X8 = df8_standardized.iloc[:, i]\n",
    "    X9 = df9_standardized.iloc[:, i]\n",
    "\n",
    "    # Combine features into a DataFrame\n",
    "    X = pd.DataFrame({\n",
    "        'rotate_value': X1,\n",
    "        'transe_value': X2,\n",
    "        'distmult_value': X3,\n",
    "        'originbert_value': X4,\n",
    "        'pubmedbert_value': X5,\n",
    "        'biobert_value': X6,\n",
    "        'glm2_value': X7,\n",
    "        'glm4_value': X8,\n",
    "        'llama3_value': X9\n",
    "    })\n",
    "\n",
    "    # Predict probabilities for the positive class\n",
    "    probabilities = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    # Store probabilities in the results DataFrame\n",
    "    probability_results.iloc[:, i] = probabilities\n",
    "\n",
    "# Set numpy print precision for better readability\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Output the probability results\n",
    "probability_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a991462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP prediction\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Initialize an empty DataFrame to store prediction probabilities\n",
    "probability_results = pd.DataFrame(\n",
    "    index=df1_standardized.index,\n",
    "    columns=[f'probability_{i}' for i in range(df1_standardized.shape[1])]\n",
    ")\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Iterate over each column to make predictions\n",
    "for i in range(df1_standardized.shape[1]):\n",
    "    # Extract the i-th column from each standardized DataFrame\n",
    "    X1 = df1_standardized.iloc[:, i]\n",
    "    X2 = df2_standardized.iloc[:, i]\n",
    "    X3 = df3_standardized.iloc[:, i]\n",
    "    X4 = df4_standardized.iloc[:, i]\n",
    "    X5 = df5_standardized.iloc[:, i]\n",
    "    X6 = df6_standardized.iloc[:, i]\n",
    "    X7 = df7_standardized.iloc[:, i]\n",
    "    X8 = df8_standardized.iloc[:, i]\n",
    "    X9 = df9_standardized.iloc[:, i]\n",
    "\n",
    "    # Combine features into a tensor of shape (num_rows, 9)\n",
    "    X = torch.tensor(\n",
    "        [[X1[j], X2[j], X3[j], X4[j], X5[j], X6[j], X7[j], X8[j], X9[j]] for j in range(len(X1))],\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    # Predict probabilities using the neural network model without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        probabilities = model(X).numpy().flatten()  # Flatten output to 1D array\n",
    "\n",
    "    # Store the probabilities in the results DataFrame\n",
    "    probability_results.iloc[:, i] = probabilities\n",
    "\n",
    "# Output the probability results\n",
    "probability_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55e41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Calculation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ranks(dictrue, df_avg):\n",
    "    \"\"\"\n",
    "    Calculate average rank for each key in dictrue based on df_avg columns.\n",
    "    Ranks are computed with ties averaged (default pandas rank behavior).\n",
    "    \"\"\"\n",
    "    rank = []\n",
    "    for i in dictrue.keys():\n",
    "        value_position = dictrue[i]\n",
    "        column_values = df_avg.iloc[:, i]\n",
    "        # Rank values in descending order, with ties averaged\n",
    "        sorted_indices = column_values.rank(ascending=False)\n",
    "        rank_value = sorted_indices[value_position]\n",
    "        rank.append(rank_value)\n",
    "    return rank\n",
    "\n",
    "def calculate_ranks_max(dictrue, df_avg):\n",
    "    \"\"\"\n",
    "    Calculate ranks using method='max', so ties take the maximum rank.\n",
    "    \"\"\"\n",
    "    rank = []\n",
    "    for i in dictrue.keys():\n",
    "        value_position = dictrue[i]\n",
    "        column_values = df_avg.iloc[:, i]\n",
    "        sorted_indices = column_values.rank(method='max', ascending=False)\n",
    "        rank_value = sorted_indices[value_position]\n",
    "        rank.append(rank_value)\n",
    "    return rank\n",
    "\n",
    "def calculate_ranks_min(dictrue, df_avg):\n",
    "    \"\"\"\n",
    "    Calculate ranks using method='min', so ties take the minimum rank.\n",
    "    \"\"\"\n",
    "    rank = []\n",
    "    for i in dictrue.keys():\n",
    "        value_position = dictrue[i]\n",
    "        column_values = df_avg.iloc[:, i]\n",
    "        sorted_indices = column_values.rank(method='min', ascending=False)\n",
    "        rank_value = sorted_indices[value_position]\n",
    "        rank.append(rank_value)\n",
    "    return rank\n",
    "\n",
    "def calculate_proportions(rank):\n",
    "    \"\"\"\n",
    "    Calculate and print statistics based on the rank list:\n",
    "    - Count and proportion of ranks equal to 1\n",
    "    - Count and proportion of ranks <= 3\n",
    "    - Count and proportion of ranks <= 10\n",
    "    - Mean rank\n",
    "    - Mean reciprocal rank (MRR)\n",
    "    \"\"\"\n",
    "    total = len(rank)\n",
    "\n",
    "    rank_1_count = sum(1 for r in rank if r == 1)\n",
    "    rank_1_proportion = rank_1_count / total\n",
    "\n",
    "    rank_3_count = sum(1 for r in rank if r <= 3)\n",
    "    rank_3_proportion = rank_3_count / total\n",
    "\n",
    "    rank_10_count = sum(1 for r in rank if r <= 10)\n",
    "    rank_10_proportion = rank_10_count / total\n",
    "\n",
    "    rank_mean = np.mean(rank)\n",
    "    rank_reciprocal_mean = np.mean(1 / np.array(rank))\n",
    "\n",
    "    print(f\"Rank = 1: {rank_1_count} ({rank_1_proportion * 100:.2f}%)\")\n",
    "    print(f\"Rank <= 3: {rank_3_count} ({rank_3_proportion * 100:.2f}%)\")\n",
    "    print(f\"Rank <= 10: {rank_10_count} ({rank_10_proportion * 100:.2f}%)\")\n",
    "    print(f\"Average Rank: {rank_mean:.2f}\")\n",
    "    print(f\"MRR: {rank_reciprocal_mean:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ranks with averaged ties\n",
    "rank = calculate_ranks(dictrue, df2_standardized)\n",
    "\n",
    "# Print rank-based evaluation metrics\n",
    "calculate_proportions(rank)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
